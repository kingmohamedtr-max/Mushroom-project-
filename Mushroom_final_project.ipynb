{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYajY81CtgFad7G/MoJcKL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingmohamedtr-max/Mushroom-project-/blob/main/Mushroom_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business case (Mushroom dataset) - Supervised Machine learning\n",
        "\n",
        "Target: (class: poisonous or not)\n",
        "\n",
        "Business case: Help the FDA (food and drug admistration) ensure safety through toxicity detection for food and drug products that contain mushrooms.\n",
        "\n",
        "Edible = e, poisonous = p\n",
        "Audience: FDA\n",
        "\n",
        "By: Mohamed Traore, Francesca Saba, Paulina Mauran and Katelyn Olifiant"
      ],
      "metadata": {
        "id": "is6eKnJ4P5Rg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIEleOblPtbt"
      },
      "outputs": [],
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# 3. Load your CSV\n",
        "# Make sure you update the path to the correct folder where your file is stored\n",
        "file_path = \"/content/drive/My Drive/secondary_data mushrooms.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 4. Display the dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "XcSPvf39QOXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "OVXGzHOsQN9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10)"
      ],
      "metadata": {
        "id": "S34OTXFDQaXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "WQpROH4aQeRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "57UvTzVah3ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "MJXrTQJOQhty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "xYy7eJ0LQjQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "Ti0VE8JCQliX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "sorted_missing_values = missing_values.sort_values(ascending=False)\n",
        "top_5_missing_columns = sorted_missing_values.head(5).index.tolist()\n",
        "\n",
        "print(\"Top 5 columns with the most missing values:\")\n",
        "print(top_5_missing_columns)\n",
        "\n",
        "# Drop the identified columns from the DataFrame\n",
        "df = df.drop(columns=top_5_missing_columns)\n",
        "\n",
        "print(\"\\nDataFrame shape after dropping columns:\", df.shape)\n",
        "\n",
        "# Verify missing values again\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "7AJ7dIgeQru4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "    if df[column].isnull().any():\n",
        "        mode_value = df[column].mode()[0] # Get the first mode if there are multiple\n",
        "        df[column].fillna(mode_value, inplace=True)\n",
        "\n",
        "print(\"Missing values after imputation:\")\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "CgpFWT61Qt5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Analysis Key Findings\n",
        "The top 5 columns with the most missing values were identified as ['veil-type', 'spore-print-color', 'veil-color', 'stem-root', 'stem-surface'].\n",
        "These 5 columns were dropped from the DataFrame, reducing its shape from an implied (61069, 21) to (61069, 16).\n",
        "After dropping the top 5 columns, missing values were still present in cap-surface, gill-attachment, gill-spacing, and ring-type.\n",
        "All remaining missing values in the DataFrame were successfully imputed using the mode of their respective columns.\n",
        "Verification confirmed that no missing values are left in the DataFrame after the imputation process.\n",
        "Insights or Next Steps\n",
        "The DataFrame is now cleaned of missing values, making it ready for further exploratory data analysis or machine learning model training.\n",
        "The high number of missing values in the dropped columns (veil-type, spore-print-color, veil-color, stem-root, stem-surface) suggests these features might be unreliable or not universally applicable, which could be investigated further if their original data source allows."
      ],
      "metadata": {
        "id": "sKAEq77YQyoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Significant Missing Values Leading to Feature Removal: Five columns (veil-type, spore-print-color, veil-color, stem-root, stem-surface) had an extremely high percentage of missing values (some over 80%). These columns were subsequently dropped from the DataFrame. This implies that these features are either largely unrecorded or unreliable in the dataset. For modeling, this means these features cannot be used directly, simplifying the model but also potentially losing information if these features are truly important and could have been imputed with more sophisticated methods or external data. The remaining missing values were imputed using the mode, which is a simple strategy but might not be optimal for all features.\n",
        "\n",
        "Positive Skewness and Outliers in Numerical Features: All three numerical features (cap-diameter, stem-height, and stem-width) exhibit positive skewness with numerous outliers on the higher end. Many machine learning algorithms assume normally distributed data or are sensitive to the presence of skewness and outliers (e.g., linear models, distance-based algorithms). Therefore, preprocessing steps such as log transformations or robust scaling (e.g., using RobustScaler or QuantileTransformer) will likely be crucial to mitigate the impact of skewness and outliers, potentially improving model performance and stability."
      ],
      "metadata": {
        "id": "gSjq74ZJSpEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Univariate analysis"
      ],
      "metadata": {
        "id": "V4hJjuCwQ3IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(f\"Categorical columns identified: {list(categorical_cols)}\")\n",
        "\n",
        "# Plot count plots for categorical columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nAnalyzing categorical column: {col}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=df, x=col, order=df[col].value_counts().index, palette='viridis')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wXvVTbQSQ5sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "print(f\"Numerical columns identified: {list(numerical_cols)}\")\n",
        "\n",
        "# Plot histograms and boxplots for numerical columns\n",
        "for col in numerical_cols:\n",
        "    print(f\"\\nAnalyzing numerical column: {col}\")\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # Histogram\n",
        "    plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot\n",
        "    sns.histplot(df[col], kde=True, bins=30)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # Boxplot\n",
        "    plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot\n",
        "    sns.boxplot(y=df[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.ylabel(col)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2QbrYridQ8r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skewness Analysis of Numerical Variables\n",
        "Skewness refers to the asymmetry in a data distribution. A distribution is positively skewed (or right-skewed) if the tail is longer on the right side, meaning there are more extreme values on the higher end. A distribution is negatively skewed (or left-skewed) if the tail is longer on the left side, indicating more extreme values on the lower end.\n",
        "\n",
        "Here's the breakdown for your numerical variables:\n",
        "\n",
        "cap-diameter: The histogram for cap-diameter shows a long tail extending to the right, and the boxplot indicates numerous outliers on the upper end. This suggests that cap-diameter is positively skewed. Most mushrooms have smaller cap diameters, but there are a considerable number with much larger ones.\n",
        "\n",
        "stem-height: Similar to cap-diameter, the stem-height histogram exhibits a tail to the right, and its boxplot shows outliers on the higher side. Therefore, stem-height is also positively skewed. Most mushrooms have shorter stems, but some have notably taller stems.\n",
        "\n",
        "stem-width: The histogram for stem-width also displays a distinct rightward tail, and the boxplot points to many outliers with greater widths. This indicates that stem-width is positively skewed. The majority of mushrooms have narrower stems, with a smaller proportion having much thicker stems.\n",
        "\n",
        "In summary, all three numerical variables (cap-diameter, stem-height, and stem-width) are positively skewed, meaning they have a concentration of data points at the lower end of their ranges and a few extreme values at the higher end. This is common in many natural measurements where a baseline exists, but occasional larger instances occur."
      ],
      "metadata": {
        "id": "RefzyvcCRCAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bivariate analysis"
      ],
      "metadata": {
        "id": "8EudbGeuRDeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'class' is the target variable\n",
        "target_variable = 'class'\n",
        "\n",
        "# Identify categorical columns, excluding the target variable itself\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.drop(target_variable, errors='ignore')\n",
        "\n",
        "print(f\"Analyzing categorical columns against target '{target_variable}': {list(categorical_cols)}\")\n",
        "\n",
        "# Plot count plots for each categorical column against the target\n",
        "for col in categorical_cols:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=df, x=col, hue=target_variable, palette='viridis', order=df[col].value_counts().index)\n",
        "    plt.title(f'Distribution of {col} by {target_variable}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Note: The request also mentioned 'Stacked bar plots or interaction plots'.\n",
        "# The countplots with 'hue' are a form of grouped bar plots showing interaction.\n",
        "# If a more complex interaction plot (e.g., between two independent categorical features vs. target) is desired,\n",
        "# please specify the features."
      ],
      "metadata": {
        "id": "4cGmNc5LRH43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=df, x=col, order=df[col].value_counts().index, palette='viridis')\n",
        "    plt.title(f'Bar Plot of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UgOVdK6RRKnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "sns.pairplot(df[numerical_cols])\n",
        "plt.suptitle('Pair Plot of Numerical Features', y=1.02) # Adjust suptitle to not overlap\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "km6tzf5hRtAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baeaa446"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Identify numerical columns (assuming 'df' is already loaded)\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "print(f\"Numerical columns identified: {list(numerical_cols)}\")\n",
        "\n",
        "# Plot boxplots for numerical columns\n",
        "for col in numerical_cols:\n",
        "    print(f\"\\nAnalyzing numerical column: {col}\")\n",
        "\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    sns.boxplot(y=df[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.ylabel(col)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariate analysis"
      ],
      "metadata": {
        "id": "Y9CkXWl4SOtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "correlation_matrix = numerical_df.corr()\n",
        "display(correlation_matrix)"
      ],
      "metadata": {
        "id": "wFclBhY1SR4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-GJUdw1SU1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentation of the correlation matrix\n",
        "\n",
        "cap-diameter and stem-width: These two features exhibit the strongest positive correlation, with a coefficient of approximately 0.70. This suggests a robust relationship where mushrooms with larger cap diameters tend to have wider stems.\n",
        "\n",
        "stem-height and stem-width: Following closely, there's a positive correlation of about 0.58 between stem height and stem width. This indicates that taller mushroom stems are generally associated with wider stems.\n",
        "\n",
        "cap-diameter and stem-height: The weakest, though still positive, correlation is observed between cap diameter and stem height, with a coefficient of approximately 0.50. This means that while larger cap diameters are generally linked to taller stems, this relationship is less pronounced compared to the other pairs.\n",
        "\n",
        "In summary, the dimensions of the mushroom (cap diameter, stem height, and stem width) all tend to increase together, but the relationship is strongest between cap-diameter and stem-width."
      ],
      "metadata": {
        "id": "3Ii8utOiSX6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outliers"
      ],
      "metadata": {
        "id": "w1xSh3nZSwOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Shape before outlier removal:\", df.shape)\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Iteratively remove outliers until none remain\n",
        "max_iterations = 10\n",
        "iteration = 0\n",
        "\n",
        "while iteration < max_iterations:\n",
        "    initial_shape = df.shape[0]\n",
        "    mask = pd.Series([True] * len(df), index=df.index)\n",
        "\n",
        "    for column in numerical_cols:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        column_mask = (df[column] >= lower_bound) & (df[column] <= upper_bound)\n",
        "        mask = mask & column_mask\n",
        "\n",
        "    df = df[mask].copy()\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    rows_removed = initial_shape - df.shape[0]\n",
        "    print(f\"Iteration {iteration + 1}: Removed {rows_removed} rows\")\n",
        "\n",
        "    if rows_removed == 0:\n",
        "        print(\"No more outliers detected!\")\n",
        "        break\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "print(\"\\nFinal shape after outlier removal:\", df.shape)\n"
      ],
      "metadata": {
        "id": "SX-GkO_vYeoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "print(\"=== Final Outlier Verification ===\\n\")\n",
        "\n",
        "total_outliers = 0\n",
        "\n",
        "for column in numerical_cols:\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Count outliers\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    outlier_count = len(outliers)\n",
        "    total_outliers += outlier_count\n",
        "\n",
        "    status = \"✓ CLEAN\" if outlier_count == 0 else \"✗ OUTLIERS FOUND\"\n",
        "    print(f\"{column}: {outlier_count} outliers {status}\")\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    sns.boxplot(y=df[column])\n",
        "    plt.title(f'{column} - {status}')\n",
        "    plt.ylabel(column)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "if total_outliers == 0:\n",
        "    print(\"✓ SUCCESS: All outliers removed! Boxplots are clean.\")\n",
        "else:\n",
        "    print(f\"✗ WARNING: {total_outliers} total outliers still present.\")\n",
        "print(f\"{'='*50}\")\n"
      ],
      "metadata": {
        "id": "pegdudA8WocA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check current state\n",
        "print(\"Current df shape:\", df.shape)\n",
        "print(\"\\nColumn names in df:\")\n",
        "print(list(df.columns))\n",
        "\n",
        "# Verify if columns were actually dropped\n",
        "expected_dropped = ['veil-type', 'spore-print-color', 'veil-color', 'stem-root', 'stem-surface']\n",
        "\n",
        "print(\"\\nChecking if columns were dropped:\")\n",
        "for col in expected_dropped:\n",
        "    if col in df.columns:\n",
        "        print(f\"  ✗ {col} - STILL PRESENT (not dropped)\")\n",
        "    else:\n",
        "        print(f\"  ✓ {col} - Dropped successfully\")\n",
        "\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum().sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "8uo9m9Q4Xv5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logisitc regression"
      ],
      "metadata": {
        "id": "lCYD_IluZMdU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a70342c"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Separate features (X) from the target variable (y)\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# 2. Identify numerical columns\n",
        "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "print(f\"Numerical features: {numerical_features}\")\n",
        "\n",
        "# 3. Identify categorical columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"Categorical features: {categorical_features}\")\n",
        "\n",
        "# 4. and 5. Create a ColumnTransformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# 6. Apply the preprocessor to X\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "print(\"\\nShape of original X:\", X.shape)\n",
        "print(\"Shape of processed X (X_processed):\", X_processed.shape)\n",
        "print(\"Target variable y head:\\n\", y.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "829ca541"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets to verify the split\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24485d47"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate a Logistic Regression model\n",
        "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Train the model using the training data\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcf128f0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg_model.predict(X_test)\n",
        "\n",
        "# Determine the index of the positive class ('p') in the model's classes\n",
        "positive_class_idx = list(log_reg_model.classes_).index('p')\n",
        "y_pred_proba = log_reg_model.predict_proba(X_test)[:, positive_class_idx] # Probability of the positive class (class 'p')\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label='p')\n",
        "recall = recall_score(y_test, y_pred, pos_label='p')\n",
        "f1 = f1_score(y_test, y_pred, pos_label='p')\n",
        "\n",
        "# For roc_auc_score, y_true must be binary (0 or 1). Convert 'p' to 1 and 'e' to 0.\n",
        "# Ensure y_test is mapped correctly to 0 and 1, where 1 is the positive class 'p'\n",
        "y_test_binary = (y_test == 'p').astype(int)\n",
        "roc_auc = roc_auc_score(y_test_binary, y_pred_proba)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=['e', 'p'])\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\nClassification Report:\\n{class_report}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dc74bc6"
      },
      "source": [
        "## Logistic Regression Model Performance Summary\n",
        "\n",
        "The Logistic Regression model has been evaluated on the test set, and its performance metrics provide a good understanding of its ability to classify mushrooms as poisonous ('p') or edible ('e').\n",
        "\n",
        "### 1. Overall Performance\n",
        "The model achieved an **Accuracy of 0.8069**, meaning it correctly classified about 80.69% of the mushrooms in the test set. However, accuracy alone can be misleading, especially with imbalanced datasets or when certain types of errors are more critical than others, as is the case here.\n",
        "\n",
        "### 2. Metric Breakdown and Business Case Relevance\n",
        "\n",
        "*   **Precision (for poisonous 'p'): 0.8189**\n",
        "    *   This means that when the model predicts a mushroom is poisonous, it is correct 81.89% of the time. In the context of the FDA ensuring safety, high precision for 'p' is important because it reduces the number of false alarms (labeling an edible mushroom as poisonous). While false alarms can lead to unnecessary product recalls or waste, they are generally less critical than missing a poisonous product.\n",
        "\n",
        "*   **Recall (for poisonous 'p'): 0.8287**\n",
        "    *   This indicates that the model correctly identified 82.87% of all actual poisonous mushrooms. For the FDA's safety mission, **recall for 'p' is paramount**. A high recall minimizes the number of false negatives – actual poisonous mushrooms that the model incorrectly classifies as edible. Missing a poisonous mushroom could have severe public health consequences.\n",
        "\n",
        "*   **F1-Score (for poisonous 'p'): 0.8238**\n",
        "    *   The F1-Score is the harmonic mean of precision and recall, providing a balance between the two. A score of 0.8238 suggests a reasonably good balance, but considering the high stakes of false negatives, recall might be a more critical single metric.\n",
        "\n",
        "*   **ROC-AUC: 0.8851**\n",
        "    *   The Area Under the Receiver Operating Characteristic Curve (ROC-AUC) measures the model's ability to distinguish between classes. An ROC-AUC of 0.8851 indicates a good discriminative power, suggesting the model is generally good at ranking poisonous mushrooms higher than edible ones.\n",
        "\n",
        "### 3. Key Insights from the Confusion Matrix\n",
        "The confusion matrix is a critical tool for understanding where the model makes mistakes:\n",
        "\n",
        "```\n",
        "[[3600 1011]\n",
        " [ 945 4573]]\n",
        "```\n",
        "(Rows represent actual classes: 'e' then 'p'. Columns represent predicted classes: 'e' then 'p'.)\n",
        "\n",
        "*   **True Negatives (TN): 3600**\n",
        "    *   The model correctly identified 3600 edible mushrooms as edible ('e'). These are correctly classified safe products.\n",
        "\n",
        "*   **False Positives (FP) / Type I Error: 1011**\n",
        "    *   The model incorrectly classified 1011 edible mushrooms as poisonous ('p'). These are false alarms. While not ideal for business (e.g., product waste), they don't pose a direct health risk.\n",
        "\n",
        "*   **False Negatives (FN) / Type II Error: 945**\n",
        "    *   The model incorrectly classified 945 poisonous mushrooms as edible ('e'). **This is the most critical error type for the FDA's business case.** These are potentially harmful products that the model deemed safe, posing a direct threat to public health.\n",
        "\n",
        "*   **True Positives (TP): 4573**\n",
        "    *   The model correctly identified 4573 poisonous mushrooms as poisonous ('p'). These are successfully detected dangerous products.\n",
        "\n",
        "### 4. Suitability for the Business Case\n",
        "Given the business case of the FDA ensuring safety, the model's performance, particularly the **945 False Negatives**, is a significant concern. While an F1-score of 0.82 and ROC-AUC of 0.88 are generally good, the high cost of a Type II error (missing a poisonous mushroom) means that even this number of false negatives is unacceptable for a safety-critical application. If 945 poisonous mushrooms are wrongly labeled as edible in the real world, it could lead to serious health issues.\n",
        "\n",
        "**Conclusion:** The current Logistic Regression model, despite its decent overall metrics, is **not yet suitable** for direct deployment in a safety-critical environment like FDA toxicity detection due to the high number of false negatives. The priority for this business case should be to **minimize False Negatives** even if it means accepting a higher rate of False Positives. Further model tuning, exploring different algorithms, or collecting more relevant features might be necessary to improve the recall for the poisonous class significantly."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=log_reg_model.classes_, yticklabels=log_reg_model.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NM4_eEJ5a68-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selction"
      ],
      "metadata": {
        "id": "quMgg15TbTk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# scale the dataset\n",
        "Scale = MinMaxScaler"
      ],
      "metadata": {
        "id": "Y9umiu-2iUVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Instantiate a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 2. Fit the LabelEncoder to the target variable y and then transform y\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "NNFwFwvIjj0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules for feature selection\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Use the cleaned 'df' available in the kernel state\n",
        "# Separate features (X_kbest) and target (y_kbest) from the cleaned df\n",
        "X_kbest = df.drop('class', axis=1)\n",
        "y_kbest = df['class']\n",
        "\n",
        "# Encode the target variable if not already encoded for this specific run\n",
        "# Using the existing label_encoder from cell acab400e\n",
        "y_kbest_encoded = label_encoder.transform(y_kbest)\n",
        "\n",
        "# Apply the preprocessor (from cell acab400e) to X_kbest to get numerical features\n",
        "X_kbest_processed = preprocessor.fit_transform(X_kbest)\n",
        "\n",
        "# Apply k-best\n",
        "k = 30\n",
        "selector = SelectKBest(score_func=f_regression, k=k) # f_regression expects numerical input\n",
        "X_new = selector.fit_transform(X_kbest_processed, y_kbest_encoded)\n",
        "\n",
        "# feature selection\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "# The 'preprocessor' is a ColumnTransformer defined in cell acab400e\n",
        "processed_feature_names = []\n",
        "for name, transformer, cols in preprocessor.transformers_:\n",
        "    if name == 'num':\n",
        "        processed_feature_names.extend(cols)\n",
        "    elif name == 'cat': # Assuming 'cat' is the name of your OneHotEncoder transformer\n",
        "        processed_feature_names.extend(transformer.get_feature_names_out(cols))\n",
        "\n",
        "all_feature_names = processed_feature_names # This is the list of all features after preprocessing\n",
        "\n",
        "selected_feature_names = [all_feature_names[i] for i in selected_indices]\n",
        "\n",
        "# print features\n",
        "print(\"Selected Features:\", selected_feature_names)"
      ],
      "metadata": {
        "id": "d39Y2a3tiW3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Best Feature Selection (`k=30`)\n",
        "\n",
        "Using `SelectKBest` with the `f_regression` scoring function to select the top 30 features from the preprocessed dataset, the following features were identified as most influential:\n",
        "\n",
        "*   `cap-diameter`\n",
        "*   `stem-height`\n",
        "*   `stem-width`\n",
        "*   `cap-shape_b`\n",
        "*   `cap-shape_o`\n",
        "*   `cap-surface_i`\n",
        "*   `cap-surface_k`\n",
        "*   `cap-surface_s`\n",
        "*   `cap-color_b`\n",
        "*   `cap-color_e`\n",
        "*   `cap-color_n`\n",
        "*   `cap-color_r`\n",
        "*   `gill-attachment_a`\n",
        "*   `gill-attachment_e`\n",
        "*   `gill-attachment_p`\n",
        "*   `gill-spacing_c`\n",
        "*   `gill-spacing_d`\n",
        "*   `gill-color_b`\n",
        "*   `gill-color_n`\n",
        "*   `gill-color_w`\n",
        "*   `stem-color_k`\n",
        "*   `stem-color_n`\n",
        "*   `stem-color_p`\n",
        "*   `stem-color_w`\n",
        "*   `stem-color_y`\n",
        "*   `ring-type_g`\n",
        "*   `ring-type_z`\n",
        "*   `habitat_g`\n",
        "*   `habitat_w`\n",
        "*   `season_w`\n",
        "\n",
        "This selection provides a broader set of features that contribute significantly to predicting the target variable."
      ],
      "metadata": {
        "id": "FolnBUH8mQnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- k = 15"
      ],
      "metadata": {
        "id": "TPn74sv4kSsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules for feature selection\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Use the cleaned 'df' available in the kernel state\n",
        "# Separate features (X_kbest) and target (y_kbest) from the cleaned df\n",
        "X_kbest = df.drop('class', axis=1)\n",
        "y_kbest = df['class']\n",
        "\n",
        "# Encode the target variable if not already encoded for this specific run\n",
        "# Using the existing label_encoder from cell acab400e\n",
        "y_kbest_encoded = label_encoder.transform(y_kbest)\n",
        "\n",
        "# Apply the preprocessor (from cell acab400e) to X_kbest to get numerical features\n",
        "X_kbest_processed = preprocessor.fit_transform(X_kbest)\n",
        "\n",
        "# Apply k-best\n",
        "k = 15\n",
        "selector = SelectKBest(score_func=f_regression, k=k) # f_regression expects numerical input\n",
        "X_new = selector.fit_transform(X_kbest_processed, y_kbest_encoded)\n",
        "\n",
        "# feature selection\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "# The 'preprocessor' is a ColumnTransformer defined in cell acab400e\n",
        "processed_feature_names = []\n",
        "for name, transformer, cols in preprocessor.transformers_:\n",
        "    if name == 'num':\n",
        "        processed_feature_names.extend(cols)\n",
        "    elif name == 'cat': # Assuming 'cat' is the name of your OneHotEncoder transformer\n",
        "        processed_feature_names.extend(transformer.get_feature_names_out(cols))\n",
        "\n",
        "all_feature_names = processed_feature_names # This is the list of all features after preprocessing\n",
        "\n",
        "selected_feature_names = [all_feature_names[i] for i in selected_indices]\n",
        "\n",
        "# print features\n",
        "print(\"Selected Features:\", selected_feature_names)"
      ],
      "metadata": {
        "id": "nvhRIGd9kXEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Best Feature Selection (k=15)\n",
        "K-Best feature selection is a statistical method that selects the top k features based on a scoring function. In this case, f_regression was used as the scoring function, which computes F-values for regression tasks. It evaluates the linear dependency between each feature and the target variable.\n",
        "\n",
        "For k=15, the following features were selected from the preprocessed dataset:\n",
        "\n",
        "cap-diameter\n",
        "stem-width\n",
        "cap-shape_b\n",
        "cap-surface_k\n",
        "cap-color_e\n",
        "gill-attachment_a\n",
        "gill-attachment_p\n",
        "gill-spacing_c\n",
        "gill-spacing_d\n",
        "gill-color_n\n",
        "gill-color_w\n",
        "stem-color_w\n",
        "ring-type_z\n",
        "habitat_g\n",
        "season_w"
      ],
      "metadata": {
        "id": "xNbEJLI2maHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- k = 8"
      ],
      "metadata": {
        "id": "0GYOBq8fkZkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules for feature selection\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Use the cleaned 'df' available in the kernel state\n",
        "# Separate features (X_kbest) and target (y_kbest) from the cleaned df\n",
        "X_kbest = df.drop('class', axis=1)\n",
        "y_kbest = df['class']\n",
        "\n",
        "# Encode the target variable if not already encoded for this specific run\n",
        "# Using the existing label_encoder from cell acab400e\n",
        "y_kbest_encoded = label_encoder.transform(y_kbest)\n",
        "\n",
        "# Apply the preprocessor (from cell acab400e) to X_kbest to get numerical features\n",
        "X_kbest_processed = preprocessor.fit_transform(X_kbest)\n",
        "\n",
        "# Apply k-best\n",
        "k = 8\n",
        "selector = SelectKBest(score_func=f_regression, k=k) # f_regression expects numerical input\n",
        "X_new = selector.fit_transform(X_kbest_processed, y_kbest_encoded)\n",
        "\n",
        "# feature selection\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "# The 'preprocessor' is a ColumnTransformer defined in cell acab400e\n",
        "processed_feature_names = []\n",
        "for name, transformer, cols in preprocessor.transformers_:\n",
        "    if name == 'num':\n",
        "        processed_feature_names.extend(cols)\n",
        "    elif name == 'cat': # Assuming 'cat' is the name of your OneHotEncoder transformer\n",
        "        processed_feature_names.extend(transformer.get_feature_names_out(cols))\n",
        "\n",
        "all_feature_names = processed_feature_names # This is the list of all features after preprocessing\n",
        "\n",
        "selected_feature_names = [all_feature_names[i] for i in selected_indices]\n",
        "\n",
        "# print features\n",
        "print(\"Selected Features:\", selected_feature_names)"
      ],
      "metadata": {
        "id": "M1VfYUgvkZNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Best Feature Selection (k=8)\n",
        "K-Best feature selection is a technique that selects the top k features based on a statistical test. It's part of the sklearn.feature_selection module and helps in reducing dimensionality by picking the features with the strongest relationship to the target variable. For this analysis, k was set to 8.\n",
        "\n",
        "The f_regression scoring function was used as the statistical test. f_regression computes the F-value for each feature, which measures the linear dependency between the feature and the target variable. A higher F-value indicates a stronger relationship. This method is suitable for numerical features and a continuous target, or a binary target treated numerically (as is the case after Label Encoding the 'class' column).\n",
        "\n",
        "When k=8, the following features were selected:\n",
        "\n",
        "cap-diameter\n",
        "stem-width\n",
        "cap-surface_k\n",
        "gill-attachment_p\n",
        "gill-spacing_d\n",
        "gill-color_w\n",
        "stem-color_w\n",
        "ring-type_z"
      ],
      "metadata": {
        "id": "8qrNwcLEmiNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- k = 4"
      ],
      "metadata": {
        "id": "Riz1gYWGkeyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules for feature selection\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# Use the cleaned 'df' available in the kernel state\n",
        "# Separate features (X_kbest) and target (y_kbest) from the cleaned df\n",
        "X_kbest = df.drop('class', axis=1)\n",
        "y_kbest = df['class']\n",
        "\n",
        "# Encode the target variable if not already encoded for this specific run\n",
        "# Using the existing label_encoder from cell acab400e\n",
        "y_kbest_encoded = label_encoder.transform(y_kbest)\n",
        "\n",
        "# Apply the preprocessor (from cell acab400e) to X_kbest to get numerical features\n",
        "X_kbest_processed = preprocessor.fit_transform(X_kbest)\n",
        "\n",
        "# Apply k-best\n",
        "k = 4\n",
        "selector = SelectKBest(score_func=f_regression, k=k) # f_regression expects numerical input\n",
        "X_new = selector.fit_transform(X_kbest_processed, y_kbest_encoded)\n",
        "\n",
        "# feature selection\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "# The 'preprocessor' is a ColumnTransformer defined in cell acab400e\n",
        "processed_feature_names = []\n",
        "for name, transformer, cols in preprocessor.transformers_:\n",
        "    if name == 'num':\n",
        "        processed_feature_names.extend(cols)\n",
        "    elif name == 'cat': # Assuming 'cat' is the name of your OneHotEncoder transformer\n",
        "        processed_feature_names.extend(transformer.get_feature_names_out(cols))\n",
        "\n",
        "all_feature_names = processed_feature_names # This is the list of all features after preprocessing\n",
        "\n",
        "selected_feature_names = [all_feature_names[i] for i in selected_indices]\n",
        "\n",
        "# print features\n",
        "print(\"Selected Features:\", selected_feature_names)"
      ],
      "metadata": {
        "id": "cXTG4WJPkgcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Best Feature Selection (k=4) Summary\n",
        "Process:\n",
        "The K-Best feature selection method, in conjunction with f_regression as the scoring function, was employed to identify the most relevant features for predicting the target variable. f_regression computes the F-value for each feature, which measures the linear dependency between the feature and the target. A higher F-value indicates a stronger relationship.\n",
        "\n",
        "For this specific selection, k was set to 4, meaning the top 4 features with the highest F-values were chosen.\n",
        "\n",
        "Selected Features (k=4):\n",
        "Based on the f_regression scoring and selecting the top 4 features, the following features were identified:\n",
        "\n",
        "cap-diameter\n",
        "stem-width\n",
        "gill-attachment_p\n",
        "stem-color_w\n",
        "\n"
      ],
      "metadata": {
        "id": "nP8WtfctlObo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Analysis Key Findings\n",
        "For k=30, 30 features were selected, including physical dimensions (cap-diameter, stem-height, stem-width) and numerous one-hot encoded categorical features related to cap shape, surface, color, gill attachment, spacing, color, stem color, ring type, habitat, and season.\n",
        "For k=15, the selection narrowed to 15 features. This set still included cap-diameter and stem-width, along with specific categorical indicators like cap-shape_b, cap-surface_k, gill-attachment_a, gill-attachment_p, gill-spacing_c, gill-spacing_d, gill-color_n, gill-color_w, stem-color_w, ring-type_z, habitat_g, and season_w.\n",
        "For k=8, only 8 features were chosen: cap-diameter, stem-width, cap-surface_k, gill-attachment_p, gill-spacing_d, gill-color_w, stem-color_w, and ring-type_z.\n",
        "For k=4, the most restrictive selection yielded the top 4 features: cap-diameter, stem-width, gill-attachment_p, and stem-color_w. These four features consistently appeared in all selections regardless of the k value.\n",
        "Insights or Next Steps\n",
        "The features cap-diameter, stem-width, gill-attachment_p, and stem-color_w are highly important for predicting the target variable, given their consistent selection across all k values.\n",
        "Further model training and evaluation should be performed using these different sets of selected features to determine the optimal k value that balances model complexity and predictive performance.\n"
      ],
      "metadata": {
        "id": "_-m4oYszm0mZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso"
      ],
      "metadata": {
        "id": "fgzh0Z7Vkky6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- aplha = 0.08"
      ],
      "metadata": {
        "id": "oUiz1x4zk7ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X_lasso_features = X_kbest_processed\n",
        "y_lasso_target = y_kbest_encoded\n",
        "\n",
        "# Scale the features (Lasso is sensitive to feature scaling)\n",
        "# Pass with_mean=False as X_lasso_features might be a sparse matrix\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_lasso_scaled = scaler.fit_transform(X_lasso_features)\n",
        "\n",
        "# Define the alpha value (you can change this to experiment)\n",
        "user_alpha = 0.08# Example alpha value, you can change this\n",
        "\n",
        "# Apply Lasso for feature selection\n",
        "lasso_model = Lasso(alpha=user_alpha, random_state=42, max_iter=10000)\n",
        "lasso_model.fit(X_lasso_scaled, y_lasso_target)\n",
        "\n",
        "print(f\"Lasso model applied with alpha: {user_alpha}\")\n",
        "\n",
        "# Identify selected features (non-zero coefficients)\n",
        "selected_lasso_indices = np.where(lasso_model.coef_ != 0)[0]\n",
        "\n",
        "# Get feature names after preprocessing (using all_feature_names from previous steps)\n",
        "selected_lasso_features = [all_feature_names[i] for i in selected_lasso_indices]\n",
        "\n",
        "print(\"\\nSelected Features by Lasso:\")\n",
        "print(selected_lasso_features)"
      ],
      "metadata": {
        "id": "jyBB3Vk0kml4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha = 0.05"
      ],
      "metadata": {
        "id": "HdkR9TuilEf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X_lasso_features = X_kbest_processed\n",
        "y_lasso_target = y_kbest_encoded\n",
        "\n",
        "# Scale the features (Lasso is sensitive to feature scaling)\n",
        "# Pass with_mean=False as X_lasso_features might be a sparse matrix\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_lasso_scaled = scaler.fit_transform(X_lasso_features)\n",
        "\n",
        "# Define the alpha value (you can change this to experiment)\n",
        "user_alpha = 0.05 # Example alpha value, you can change this\n",
        "\n",
        "# Apply Lasso for feature selection\n",
        "lasso_model = Lasso(alpha=user_alpha, random_state=42, max_iter=10000)\n",
        "lasso_model.fit(X_lasso_scaled, y_lasso_target)\n",
        "\n",
        "print(f\"Lasso model applied with alpha: {user_alpha}\")\n",
        "\n",
        "# Identify selected features (non-zero coefficients)\n",
        "selected_lasso_indices = np.where(lasso_model.coef_ != 0)[0]\n",
        "\n",
        "# Get feature names after preprocessing (using all_feature_names from previous steps)\n",
        "selected_lasso_features = [all_feature_names[i] for i in selected_lasso_indices]\n",
        "\n",
        "print(\"\\nSelected Features by Lasso:\")\n",
        "print(selected_lasso_features)"
      ],
      "metadata": {
        "id": "4tEy8Gj8lI_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha = 0.03"
      ],
      "metadata": {
        "id": "YPltBtdZlT0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X_lasso_features = X_kbest_processed\n",
        "y_lasso_target = y_kbest_encoded\n",
        "\n",
        "# Scale the features (Lasso is sensitive to feature scaling)\n",
        "# Pass with_mean=False as X_lasso_features might be a sparse matrix\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_lasso_scaled = scaler.fit_transform(X_lasso_features)\n",
        "\n",
        "# Define the alpha value (you can change this to experiment)\n",
        "user_alpha = 0.03 # Example alpha value, you can change this\n",
        "\n",
        "# Apply Lasso for feature selection\n",
        "lasso_model = Lasso(alpha=user_alpha, random_state=42, max_iter=10000)\n",
        "lasso_model.fit(X_lasso_scaled, y_lasso_target)\n",
        "\n",
        "print(f\"Lasso model applied with alpha: {user_alpha}\")\n",
        "\n",
        "# Identify selected features (non-zero coefficients)\n",
        "selected_lasso_indices = np.where(lasso_model.coef_ != 0)[0]\n",
        "\n",
        "# Get feature names after preprocessing (using all_feature_names from previous steps)\n",
        "selected_lasso_features = [all_feature_names[i] for i in selected_lasso_indices]\n",
        "\n",
        "print(\"\\nSelected Features by Lasso:\")\n",
        "print(selected_lasso_features)"
      ],
      "metadata": {
        "id": "Op3XmfNrlmeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d390020"
      },
      "source": [
        "## Document Lasso (alpha=0.08)\n",
        "\n",
        "\n",
        "\n",
        "### Lasso Feature Selection Process\n",
        "\n",
        "Lasso (Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces. It adds a penalty equivalent to the absolute value of the magnitude of coefficients to the loss function. This type of regularization (L1 regularization) has the effect of shrinking some coefficients exactly to zero. When a coefficient becomes zero, the corresponding feature is effectively removed from the model, thus performing feature selection.\n",
        "\n",
        "### Features Selected with `alpha = 0.08`\n",
        "\n",
        "With a regularization strength (`alpha`) set to **0.08**, the Lasso model identified the following features as most relevant (i.e., their coefficients were not shrunk to zero):\n",
        "\n",
        "*   `stem-width`\n",
        "*   `gill-attachment_p`\n",
        "*   `stem-color_w`\n",
        "*   `ring-type_z`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b401f522"
      },
      "source": [
        "## Document Lasso (alpha=0.05)\n",
        "\n",
        "### Lasso Feature Selection Process\n",
        "Lasso (Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces. It achieves this by adding a penalty equivalent to the absolute value of the magnitude of coefficients to the loss function. This L1 regularization technique can shrink some coefficients exactly to zero, effectively performing automatic feature selection by excluding less important features from the model.\n",
        "\n",
        "### Features Selected with `alpha = 0.05`\n",
        "With a regularization strength (`alpha`) set to **0.05**, the Lasso model identified the following features as most relevant (i.e., their coefficients were not shrunk to zero):\n",
        "\n",
        "*   cap-diameter\n",
        "*   stem-width\n",
        "*   cap-surface_k\n",
        "*   cap-color_e\n",
        "*   cap-color_n\n",
        "*   cap-color_r\n",
        "*   gill-attachment_p\n",
        "*   gill-spacing_c\n",
        "*   gill-spacing_d\n",
        "*   gill-color_w\n",
        "*   stem-color_w\n",
        "*   ring-type_z\n",
        "*   season_w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1863783"
      },
      "source": [
        "## Document Lasso (alpha=0.03)\n",
        "\n",
        "### Lasso Feature Selection Process\n",
        "Lasso (Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model. It uses L1 regularization, which adds a penalty equal to the absolute value of the magnitude of coefficients to the loss function. This type of regularization has the effect of shrinking some coefficients to exactly zero, effectively performing feature selection by excluding those features from the model.\n",
        "\n",
        "The `alpha` parameter controls the strength of this penalty. A higher `alpha` value means more regularization and more coefficients being driven to zero, leading to a sparser model (fewer selected features). Conversely, a lower `alpha` value means less regularization and more features being retained.\n",
        "\n",
        "### Selected Features with alpha = 0.03\n",
        "When the regularization strength (`alpha`) was set to 0.03, the Lasso model identified the following features as most relevant for prediction:\n",
        "\n",
        "*   `cap-diameter`\n",
        "*   `stem-width`\n",
        "*   `cap-shape_b`\n",
        "*   `cap-shape_o`\n",
        "*   `cap-surface_h`\n",
        "*   `cap-surface_i`\n",
        "*   `cap-surface_k`\n",
        "*   `cap-surface_s`\n",
        "*   `cap-color_b`\n",
        "*   `cap-color_e`\n",
        "*   `cap-color_n`\n",
        "*   `cap-color_r`\n",
        "*   `gill-attachment_e`\n",
        "*   `gill-attachment_p`\n",
        "*   `gill-spacing_c`\n",
        "*   `gill-spacing_d`\n",
        "*   `gill-color_n`\n",
        "*   `gill-color_w`\n",
        "*   `stem-color_g`\n",
        "*   `stem-color_p`\n",
        "*   `stem-color_w`\n",
        "*   `ring-type_g`\n",
        "*   `ring-type_z`\n",
        "*   `habitat_g`\n",
        "*   `habitat_l`\n",
        "*   `habitat_w`\n",
        "*   `season_s`\n",
        "*   `season_w`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397b1ad5"
      },
      "source": [
        "### Data Analysis Key Findings\n",
        "*   **Impact of Regularization Strength**: As the Lasso regularization strength (alpha) decreased from 0.08 to 0.03, the number of selected features progressively increased, indicating that weaker regularization retains more features. Specifically, `alpha = 0.08` selected 4 features, `alpha = 0.05` selected 13 features, and `alpha = 0.03` selected 28 features.\n",
        "*   **Consistently Selected Features**: The features `stem-width`, `gill-attachment_p`, `stem-color_w`, and `ring-type_z` were consistently selected across all tested alpha values (0.08, 0.05, and 0.03), suggesting their strong relevance to the model.\n",
        "*   **Increasing Feature Inclusion with Lower Alpha**: With `alpha = 0.05`, features like `cap-diameter`, `cap-surface_k`, `cap-color_e`, `cap-color_n`, `cap-color_r`, `gill-spacing_c`, `gill-spacing_d`, `gill-color_w`, and `season_w` were included in addition to the ones selected at `alpha = 0.08`. At `alpha = 0.03`, an even broader set of features including various `cap-shape`, `cap-surface`, `cap-color`, `gill-attachment`, `gill-spacing`, `gill-color`, `stem-color`, `ring-type`, `habitat`, and `season` categories were deemed relevant.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The analysis clearly illustrates the trade-off between model simplicity (fewer features) and potential predictive power as regularization strength is adjusted. Selecting an optimal alpha value requires balancing these aspects, often through cross-validation.\n",
        "*   The consistently selected features are strong candidates for inclusion in simpler, more interpretable models or for further domain-specific investigation, as they demonstrate robustness across varying regularization penalties.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trees"
      ],
      "metadata": {
        "id": "MnXSKv5LnjtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # Changed to Classifier for classification task\n",
        "import pandas as pd\n",
        "\n",
        "# Reuse preprocessed data from previous steps\n",
        "X_dtree = X_kbest_processed\n",
        "y_dtree = y_kbest_encoded\n",
        "\n",
        "# Initialize and fit the Decision Tree Classifier\n",
        "tree_classifier = DecisionTreeClassifier(random_state=42) # Added random_state for reproducibility\n",
        "tree_classifier.fit(X_dtree, y_dtree)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = tree_classifier.feature_importances_ # Corrected typo\n",
        "\n",
        "# Create a DataFrame for better visualization and sorting\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': all_feature_names, # Using all_feature_names from preprocessing\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print sorted features and their importances\n",
        "print(\"Decision Tree Feature Importances:\")\n",
        "for index, row in importance_df.iterrows():\n",
        "    print(f\"{row['Feature']}: {row['Importance']:.4f}\")"
      ],
      "metadata": {
        "id": "o2qMW7ZYnk4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate dynamic figure height: 0.35 inches per feature usually works well\n",
        "fig_height = len(importance_df) * 0.35\n",
        "\n",
        "plt.figure(figsize=(12, fig_height))\n",
        "\n",
        "sns.barplot(x='Importance', y='Feature', hue='Feature', data=importance_df, palette='viridis', legend=False)\n",
        "plt.title('Decision Tree Feature Importances (All Features)')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "smnDKukNnp4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----- 1. Create train/test split for the FULL dataset -----\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X_kbest_processed,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# ----- 2. Fit a shallow tree for visualization -----\n",
        "viz_dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "viz_dt_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "# ----- 3. Plot the tree -----\n",
        "plt.figure(figsize=(25, 15))\n",
        "plot_tree(\n",
        "    viz_dt_model,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10,\n",
        "    feature_names=all_feature_names,\n",
        "    class_names=label_encoder.classes_,\n",
        ")\n",
        "\n",
        "plt.title(\"Decision Tree Classifier Visualization (Max Depth = 3)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R6nLA56boMJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Graph\n",
        "The Decision Tree graph provides a visual representation of how the model makes classifications based on your features. Here's a breakdown of its components and how to interpret it:\n",
        "\n",
        "Nodes: Each box in the tree is called a node.\n",
        "\n",
        "Root Node: The very top node is where the decision-making process begins.\n",
        "Internal (Decision) Nodes: These are nodes that have branches leading to other nodes. They contain a condition (e.g., stem-width <= X.XX) that splits the data. If the condition is true, the data goes down one path; if false, it goes down the other.\n",
        "Leaf Nodes: These are the terminal nodes of the tree (they don't branch further). They contain the final prediction (class) for the samples that reach that node.\n",
        "Split Conditions: Each internal node contains a condition based on a feature (e.g., stem-width <= 0.437). Samples are directed left or right based on whether they satisfy this condition.\n",
        "\n",
        "gini: This value represents the Gini impurity of the node. Gini impurity is a measure of the purity of the node. A gini of 0 means the node is perfectly pure (all samples belong to the same class), while a higher gini (up to 0.5 for binary classification) indicates a more mixed set of classes. The tree aims to find splits that reduce Gini impurity.\n",
        "\n",
        "samples: This indicates the number of samples that reached this particular node.\n",
        "\n",
        "value: This is an array showing the count of samples per class in that node. For example, value = [X, Y] means there are X samples of class 'e' (edible) and Y samples of class 'p' (poisonous) in that node.\n",
        "\n",
        "class: This is the predicted class for the majority of samples in that node. In a leaf node, this is the final prediction for any sample reaching it.\n",
        "\n",
        "max_depth=3: You explicitly set max_depth=3 when creating viz_dt_model. This means the tree will have at most 3 levels of decisions (excluding the root node itself), keeping the visualization simple and preventing overfitting for this visual example.\n",
        "\n",
        "Feature Names (feature_names) and Class Names (class_names): The feature_names=all_feature_names and class_names=label_encoder.classes_ arguments ensure that the nodes are labeled with meaningful feature names and class labels ('e' for edible, 'p' for poisonous), making the tree easy to understand.\n",
        "\n",
        "How to Interpret a Prediction: To predict the class of a new mushroom, you start at the root node and follow the path down the tree by evaluating the conditions at each internal node until you reach a leaf node. The class indicated in the leaf node is the model's prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "QkBsDg4qogLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the Decision Tree feature importances previously calculated and visualized, the features that exhibit the highest importance scores are considered the most influential in the model's decision-making process for classifying mushrooms as poisonous or edible.\n",
        "\n",
        "Looking at the importance_df from the Decision Tree:\n",
        "\n",
        "stem-width (0.1364)\n",
        "stem-height (0.0795)\n",
        "stem-color_w (0.0612)\n",
        "gill-spacing_c (0.0588)\n",
        "cap-diameter (0.0545)\n",
        "These features are important because Decision Trees work by finding the best splits in the data to separate classes, and features with higher importance scores are those that lead to significant reductions in impurity (like Gini impurity) across the tree's nodes. Essentially, these features are frequently used early in the tree-building process to make crucial distinctions between mushroom classes. For example, stem-width and cap-diameter are numerical features that allow the tree to create thresholds that effectively divide data points, while stem-color_w and gill-spacing_c (likely representing specific categories of stem color and gill spacing) are categorical features that, when present or absent, strongly correlate with one class over another"
      ],
      "metadata": {
        "id": "kK8Q1EMmpPIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chi-square"
      ],
      "metadata": {
        "id": "Vnj1bAB2pQL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Get the names of the one-hot encoded categorical features from the preprocessor\n",
        "# categorical_features and preprocessor are available from earlier steps\n",
        "cat_transformer = preprocessor.named_transformers_['cat']\n",
        "one_hot_categorical_feature_names = cat_transformer.get_feature_names_out(categorical_features)\n",
        "\n",
        "# Create a mask for selecting only the one-hot encoded features from X_processed\n",
        "# Assuming numerical features are at the beginning of X_processed\n",
        "num_features_count = len(numerical_features)\n",
        "# The one-hot encoded features start after the numerical features\n",
        "X_categorical_processed = X_processed[:, num_features_count:]\n",
        "\n",
        "# Ensure X_categorical_processed is non-negative for chi2 (which it should be after OneHotEncoding)\n",
        "# and convert to dense array if it's a sparse matrix\n",
        "if hasattr(X_categorical_processed, 'toarray'):\n",
        "    X_categorical_processed_dense = X_categorical_processed.toarray()\n",
        "else:\n",
        "    X_categorical_processed_dense = X_categorical_processed\n",
        "\n",
        "# Apply SelectKBest with chi2 scoring function\n",
        "# We don't specify k here, just get scores for all categorical features\n",
        "chi2_selector = SelectKBest(chi2, k='all')\n",
        "chi2_selector.fit(X_categorical_processed_dense, y_encoded)\n",
        "\n",
        "# Get the scores (chi2 statistics) and p-values\n",
        "chi2_scores = chi2_selector.scores_\n",
        "chi2_pvalues = chi2_selector.pvalues_\n",
        "\n",
        "# Create a DataFrame to display the chi-square results\n",
        "chi2_results_df = pd.DataFrame({\n",
        "    'Feature': one_hot_categorical_feature_names,\n",
        "    'Chi2_Score': chi2_scores,\n",
        "    'P_Value': chi2_pvalues\n",
        "})\n",
        "\n",
        "# Sort by Chi2 Score in descending order\n",
        "chi2_results_df = chi2_results_df.sort_values(by='Chi2_Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"Chi-Square Test Results for Categorical Features (Sorted by Score):\\n\")\n",
        "display(chi2_results_df)"
      ],
      "metadata": {
        "id": "qcTDLgB5qE44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "344b924f"
      },
      "source": [
        "## Chi-Square Feature Selection Documentation\n",
        "\n",
        "### Method Overview\n",
        "Chi-Square ($\\\\chi^2$) feature selection is a statistical test used in feature selection to determine the dependency between categorical variables. In the context of classification, it helps assess how strongly a categorical feature is related to the categorical target variable. The null hypothesis for the Chi-Square test states that there is no relationship between the two categorical variables (i.e., they are independent).\n",
        "\n",
        "**How it works:**\n",
        "- It calculates the Chi-Square statistic for each categorical feature against the target variable.\n",
        "- A higher Chi-Square score indicates a stronger dependency between the feature and the target, suggesting that changes in the feature's categories are significantly associated with changes in the target variable's categories.\n",
        "- A lower P-value indicates that the observed relationship is statistically significant, meaning we can reject the null hypothesis of independence.\n",
        "\n",
        "### Application in this Analysis\n",
        "In this analysis, `SelectKBest` with the `chi2` scoring function was applied to the one-hot encoded categorical features (`X_categorical_processed_dense`) against the numerically encoded target variable (`y_encoded`). The numerical features were excluded from this test as Chi-Square is specifically designed for categorical data.\n",
        "\n",
        "### Key Findings from Chi-Square Test Results\n",
        "From the `chi2_results_df`, sorted by `Chi2_Score`:\n",
        "\n",
        "*   **Highest Importance**: Features such as `gill-attachment_p`, `ring-type_z`, and `stem-color_w` exhibit the highest Chi2 scores and extremely low P-values (close to zero). This indicates a very strong and statistically significant relationship between these specific categorical attributes and the mushroom's `class` (poisonous or edible).\n",
        "\n",
        "*   **Strong Predictors**: Several other features, including `cap-surface_k`, `gill-color_w`, `gill-color_n`, and `cap-shape_b`, also show high Chi2 scores and very low P-values, suggesting they are highly influential in predicting the target variable.\n",
        "\n",
        "*   **Lowest Importance**: Features like `cap-shape_s`, `stem-color_l`, `does-bruise-or-bleed_f`, `gill-attachment_x`, and `does-bruise-or-bleed_t` show very low Chi2 scores and high P-values (closer to 1), indicating a weak or no statistically significant relationship with the target variable.\n",
        "\n",
        "**Conclusion:**\n",
        "The Chi-Square test successfully identified the most influential categorical features. These highly correlated features are strong candidates for inclusion in predictive models, while features with low scores and high P-values might be considered less important or even removed to reduce model complexity without significant loss of predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "vF5mpTtYqbAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree"
      ],
      "metadata": {
        "id": "sGEBWA1PqzlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# --- Data Preparation and Preprocessing ---\n",
        "# Separate features (X) from the target (y) from the cleaned df\n",
        "X_raw = df.drop('class', axis=1)\n",
        "y_raw = df['class']\n",
        "\n",
        "\n",
        "# Encode target variable y numerically (assuming label_encoder is already fitted)\n",
        "y_encoded = label_encoder.fit_transform(y_raw)\n",
        "\n",
        "\n",
        "# Apply the preprocessor to X (scaling numerical, one-hot encoding categorical)\n",
        "# Ensure output is dense (preprocessor might output sparse)\n",
        "X_processed_dense = preprocessor.fit_transform(X_raw)\n",
        "if hasattr(X_processed_dense, 'toarray'):\n",
        "    X_processed_dense = X_processed_dense.toarray()\n",
        "\n",
        "\n",
        "# 1. Split the data into training and testing sets (using all features)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed_dense, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"\\nShape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "\n",
        "# 2. Train Decision Tree Model with hyperparameters directly\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    max_features='sqrt',\n",
        "    splitter='best',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nTraining Decision Tree model...\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"HYPERPARAMETERS USED\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  - criterion: gini\")\n",
        "print(f\"  - max_depth: 10\")\n",
        "print(f\"  - min_samples_split: 5\")\n",
        "print(f\"  - min_samples_leaf: 2\")\n",
        "print(f\"  - max_features: sqrt\")\n",
        "print(f\"  - splitter: best\")\n",
        "\n",
        "\n",
        "# 3. Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "# 4. Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "class_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DECISION TREE MODEL EVALUATION\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\nClassification Report:\\n{class_report}\")\n",
        "\n",
        "\n",
        "# 5. Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Decision Tree Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x-yf137_N47Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive bayes model"
      ],
      "metadata": {
        "id": "arU0D5lCrpQm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e006629f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Split the data (all preprocessed features) into training and testing sets\n",
        "# Using X_processed (all preprocessed features) and y_encoded (numerically encoded target)\n",
        "X_train_nb_full, X_test_nb_full, y_train_nb_full, y_test_nb_full = train_test_split(\n",
        "    X_processed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Convert sparse matrices to dense arrays for GaussianNB\n",
        "# X_processed is already sparse due to OneHotEncoder.toarray()\n",
        "# We should convert the split training and testing sets\n",
        "if hasattr(X_train_nb_full, 'toarray'):\n",
        "    X_train_nb_full = X_train_nb_full.toarray()\n",
        "if hasattr(X_test_nb_full, 'toarray'):\n",
        "    X_test_nb_full = X_test_nb_full.toarray()\n",
        "\n",
        "print(f\"Shape of X_train_nb_full: {X_train_nb_full.shape}\")\n",
        "print(f\"Shape of X_test_nb_full: {X_test_nb_full.shape}\")\n",
        "print(f\"Shape of y_train_nb_full: {y_train_nb_full.shape}\")\n",
        "print(f\"Shape of y_test_nb_full: {y_test_nb_full.shape}\")\n",
        "\n",
        "# 2. Train Gaussian Naive Bayes Model with all features\n",
        "# Instantiate a Gaussian Naive Bayes classifier\n",
        "nb_model_full = GaussianNB()\n",
        "\n",
        "# Train the model using the training data\n",
        "nb_model_full.fit(X_train_nb_full, y_train_nb_full)\n",
        "\n",
        "print(\"\\nGaussian Naive Bayes model trained successfully with all preprocessed features.\")\n",
        "\n",
        "# 3. Evaluate Naive Bayes Model\n",
        "# Make predictions on the test set\n",
        "y_pred_nb_full = nb_model_full.predict(X_test_nb_full)\n",
        "y_pred_proba_nb_full = nb_model_full.predict_proba(X_test_nb_full)[:, 1] # Probability of the positive class (class 'p' or 1)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_nb_full = accuracy_score(y_test_nb_full, y_pred_nb_full)\n",
        "precision_nb_full = precision_score(y_test_nb_full, y_pred_nb_full, pos_label=1)\n",
        "recall_nb_full = recall_score(y_test_nb_full, y_pred_nb_full, pos_label=1)\n",
        "f1_nb_full = f1_score(y_test_nb_full, y_pred_nb_full, pos_label=1)\n",
        "roc_auc_nb_full = roc_auc_score(y_test_nb_full, y_pred_proba_nb_full)\n",
        "conf_matrix_nb_full = confusion_matrix(y_test_nb_full, y_pred_nb_full, labels=[0, 1]) # 0 for 'e', 1 for 'p'\n",
        "class_report_nb_full = classification_report(y_test_nb_full, y_pred_nb_full, target_names=label_encoder.classes_)\n",
        "\n",
        "print(f\"\\nGaussian Naive Bayes Model Evaluation (using ALL preprocessed features):\")\n",
        "print(f\"Accuracy: {accuracy_nb_full:.4f}\")\n",
        "print(f\"Precision: {precision_nb_full:.4f}\")\n",
        "print(f\"Recall: {recall_nb_full:.4f}\")\n",
        "print(f\"F1-Score: {f1_nb_full:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_nb_full:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix_nb_full}\")\n",
        "print(f\"\\nClassification Report:\\n{class_report_nb_full}\")\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_nb_full, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Gaussian Naive Bayes Confusion Matrix (All Preprocessed Features)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac0e77fa"
      },
      "source": [
        "## Gaussian Naive Bayes Model Performance Summary (All Preprocessed Features)\n",
        "\n",
        "The Gaussian Naive Bayes model was trained and evaluated using all preprocessed features. Its performance is as follows:\n",
        "\n",
        "### 1. Overall Performance\n",
        "- **Accuracy: 0.7183**\n",
        "- **Precision (for poisonous 'p'): 0.8189**\n",
        "- **Recall (for poisonous 'p'): 0.6206**\n",
        "- **F1-Score (for poisonous 'p'): 0.7061**\n",
        "- **ROC-AUC: 0.8029**\n",
        "\n",
        "### 2. Key Insights from the Confusion Matrix\n",
        "```\n",
        "[[3849  758]\n",
        " [2095 3427]]\n",
        "```\n",
        "- **True Negatives (TN): 3849** (Edible correctly classified as edible)\n",
        "- **False Positives (FP): 758** (Edible incorrectly classified as poisonous)\n",
        "- **False Negatives (FN): 2095** (Poisonous incorrectly classified as edible)\n",
        "- **True Positives (TP): 3427** (Poisonous correctly classified as poisonous)\n",
        "\n",
        "### 3. Suitability for the Business Case\n",
        "**The Gaussian Naive Bayes model is not suitable for the FDA's safety-critical mission.** The most critical metric for the FDA is minimizing **False Negatives**, as these represent poisonous mushrooms that are incorrectly labeled as safe, posing a severe public health risk. With **2095 False Negatives**, this model performs significantly worse than both the Logistic Regression and Decision Tree models in this crucial aspect. Its low recall for the poisonous class (0.6206) makes it a high-risk option for deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9cd331d"
      },
      "source": [
        "## Decision Tree Model Performance Summary (K-Best Features, Tuned Hyperparameters)\n",
        "\n",
        "The Decision Tree model was trained on the K-best selected features with specific hyperparameters (`max_depth=10`, `min_samples_split=5`, `min_samples_leaf=2`, `max_features='sqrt'`). Here's its evaluation:\n",
        "\n",
        "### 1. Overall Performance\n",
        "- **Accuracy: 0.7855**\n",
        "- **Precision (for poisonous 'p'): 0.9273**\n",
        "- **Recall (for poisonous 'p'): 0.6581**\n",
        "- **F1-Score (for poisonous 'p'): 0.7698**\n",
        "- **ROC-AUC: 0.8733**\n",
        "\n",
        "### 2. Key Insights from the Confusion Matrix\n",
        "```\n",
        "[[4322  285]\n",
        " [1888 3634]]\n",
        "```\n",
        "- **True Negatives (TN): 4322** (Edible correctly classified as edible)\n",
        "- **False Positives (FP): 285** (Edible incorrectly classified as poisonous)\n",
        "- **False Negatives (FN): 1888** (Poisonous incorrectly classified as edible)\n",
        "- **True Positives (TP): 3634** (Poisonous correctly classified as poisonous)\n",
        "\n",
        "### 3. Suitability for the Business Case\n",
        "**This Decision Tree model, with these specific hyperparameters, is not suitable for the FDA's safety mission.** Despite a decent overall accuracy, the **1888 False Negatives** are still far too high for a safety-critical application. This performance is a step down from a Decision Tree with default parameters (which had only 45 FNs) and is worse even than the initial Logistic Regression model. It indicates that these specific hyperparameter choices led to a model that is less effective at identifying poisonous mushrooms, leading to unacceptable public health risks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVC"
      ],
      "metadata": {
        "id": "BCtVBumlshlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure X_processed is dense for SVC\n",
        "if hasattr(X_processed, 'toarray'):\n",
        "    X_processed_dense = X_processed.toarray()\n",
        "else:\n",
        "    X_processed_dense = X_processed\n",
        "\n",
        "X_train_svc, X_test_svc, y_train_svc, y_test_svc = train_test_split(\n",
        "    X_processed_dense,\n",
        "    y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Shape of X_train_svc: {X_train_svc.shape}\")\n",
        "print(f\"Shape of X_test_svc: {X_test_svc.shape}\")\n",
        "print(f\"Shape of y_train_svc: {y_train_svc.shape}\")\n",
        "print(f\"Shape of y_test_svc: {y_test_svc.shape}\")\n"
      ],
      "metadata": {
        "id": "g9fzDq9m0TzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC(\n",
        "    C=0.1,\n",
        "    gamma=0.01,\n",
        "    kernel='rbf',\n",
        "    random_state=42,\n",
        "    probability=True\n",
        ")\n",
        "\n",
        "print(\"\\nTraining SVC model (C=0.1, gamma=0.01, kernel='rbf')...\")\n",
        "svc_model.fit(X_train_svc, y_train_svc)\n",
        "print(\"\\nSVC model trained successfully.\")\n"
      ],
      "metadata": {
        "id": "VunP1hf-0XUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predictions\n",
        "y_pred_svc = svc_model.predict(X_test_svc)\n",
        "y_pred_proba_svc = svc_model.predict_proba(X_test_svc)[:, 1]\n",
        "\n",
        "# Metrics\n",
        "accuracy_svc = accuracy_score(y_test_svc, y_pred_svc)\n",
        "precision_svc = precision_score(y_test_svc, y_pred_svc, pos_label=1)\n",
        "recall_svc = recall_score(y_test_svc, y_pred_svc, pos_label=1)\n",
        "f1_svc = f1_score(y_test_svc, y_pred_svc, pos_label=1)\n",
        "roc_auc_svc = roc_auc_score(y_test_svc, y_pred_proba_svc)\n",
        "conf_matrix_svc = confusion_matrix(y_test_svc, y_pred_svc, labels=[0, 1])\n",
        "class_report_svc = classification_report(\n",
        "    y_test_svc, y_pred_svc, target_names=label_encoder.classes_\n",
        ")\n",
        "\n",
        "print(f\"\\nSVC Model Evaluation (C=0.1, gamma=0.01, kernel='rbf'):\")\n",
        "print(f\"Accuracy:  {accuracy_svc:.4f}\")\n",
        "print(f\"Precision: {precision_svc:.4f}\")\n",
        "print(f\"Recall:    {recall_svc:.4f}\")\n",
        "print(f\"F1-Score:  {f1_svc:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_svc:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix_svc}\")\n",
        "print(f\"False Negatives (Critical for FDA): {conf_matrix_svc[1, 0]}\")\n",
        "print(f\"\\nClassification Report:\\n{class_report_svc}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    conf_matrix_svc,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=True,\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('SVC Confusion Matrix (C=0.1, gamma=0.01)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X58YcpYJ0XIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the corrected summary for that specific SVC model:\n",
        "\n",
        "SVC Model Evaluation (C=0.1, gamma=0.01, kernel='rbf'):\n",
        "\n",
        "Accuracy: 0.8537\n",
        "Precision (for poisonous 'p'): 0.8587\n",
        "Recall (for poisonous 'p'): 0.8758\n",
        "F1-Score: 0.8671\n",
        "ROC-AUC: 0.9063\n",
        "Confusion Matrix:\n",
        "\n",
        "[[3811  796]\n",
        " [ 686 4836]]\n",
        "False Negatives (FN): 686 - This means 686 poisonous mushrooms were incorrectly classified as edible.\n",
        "Suitability for Business Case: While the model shows good overall metrics, these 686 False Negatives are still a concern for the FDA's safety mission. This number is lower than the initial Logistic Regression model (945 FNs) and significantly better than both Naive Bayes models (2095 FNs with all features, 4371 FNs with Lasso features). However, it is still substantially higher than the best-performing Decision Tree (45 FNs) and KNN (1 FN) models."
      ],
      "metadata": {
        "id": "fjjsqm79RurQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# naive bayes with k = 15"
      ],
      "metadata": {
        "id": "oN26kKh_KKWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 1. Ensure dense features\n",
        "X_dense = X_processed.toarray() if hasattr(X_processed, \"toarray\") else X_processed\n",
        "\n",
        "# 2. Select top 15 features with KBest\n",
        "selector = SelectKBest(score_func=f_classif, k=15)\n",
        "X_sel = selector.fit_transform(X_dense, y_encoded)\n",
        "\n",
        "selected_idx = selector.get_support(indices=True)\n",
        "selected_features = [all_feature_names[i] for i in selected_idx]\n",
        "print(\"Selected features:\", selected_features)\n",
        "\n",
        "# 3. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sel, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# 4. Train Gaussian Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predictions and probabilities\n",
        "y_pred = nb.predict(X_test)\n",
        "y_proba = nb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 6. Metrics\n",
        "accuracy  = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "recall    = recall_score(y_test, y_pred, pos_label=1)\n",
        "f1        = f1_score(y_test, y_pred, pos_label=1)\n",
        "roc_auc   = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"\\n=== GaussianNB with KBest (k=15) ===\")\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")\n",
        "print(f\"ROC-AUC  : {roc_auc:.4f}\")\n",
        "\n",
        "# 7. Confusion matrix + classification report\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "fn = cm[1, 0]\n",
        "print(\"\\nConfusion matrix:\\n\", cm)\n",
        "print(f\"False negatives (poisonous → edible): {fn}\")\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# 8. Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"GaussianNB Confusion Matrix (KBest k=15)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jZCTEd0JMDcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2af7217"
      },
      "source": [
        "## Naive Bayes Model Performance Summary (K-Best k=15 Features)\n",
        "\n",
        "The Gaussian Naive Bayes model was trained using the top 15 features selected by `SelectKBest` with `f_classif`. Its performance on the test set is summarized below:\n",
        "\n",
        "### 1. Overall Performance\n",
        "- **Accuracy: 0.5710**\n",
        "- **Precision (for poisonous 'p'): 0.9318**\n",
        "- **Recall (for poisonous 'p'): 0.2300**\n",
        "- **F1-Score (for poisonous 'p'): 0.3689**\n",
        "- **ROC-AUC: 0.7696**\n",
        "\n",
        "### 2. Key Insights from the Confusion Matrix\n",
        "```\n",
        "[[4514   93]\n",
        " [4252 1270]]\n",
        "```\n",
        "-   **True Negatives (TN): 4514** (Edible correctly classified as edible)\n",
        "-   **False Positives (FP): 93** (Edible incorrectly classified as poisonous)\n",
        "-   **False Negatives (FN): 4252** (Poisonous incorrectly classified as edible)\n",
        "-   **True Positives (TP): 1270** (Poisonous correctly classified as poisonous)\n",
        "\n",
        "### 3. Suitability for the Business Case\n",
        "**The Gaussian Naive Bayes model with K-best (k=15) feature selection is highly unsuitable for the FDA's safety-critical mission.** The most critical metric for this business case is the minimization of **False Negatives**, which represent poisonous mushrooms incorrectly classified as edible. This model produced an alarmingly high **4252 False Negatives**, meaning approximately 77% of actual poisonous mushrooms in the test set were missed (Recall for poisonous 'p' is only 0.2300).\n",
        "\n",
        "This performance is significantly worse than other models considered (Logistic Regression, Decision Tree, SVC, KNN) and poses an extreme public health risk. While its precision for the poisonous class is relatively high, its extremely poor recall makes it a dangerous option for deployment in a scenario where missing poisonous items has severe consequences."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive bayes with lasso alpha(0.05)"
      ],
      "metadata": {
        "id": "378NFVlLNSJk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "697f3ea3"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Set the Lasso regularization strength\n",
        "user_alpha = 0.05\n",
        "\n",
        "# 2. Ensure X_processed is dense (it's already handled as a dense array or converts to dense in previous steps)\n",
        "# For safety, explicitly convert if it's not already dense\n",
        "X_dense = X_processed.toarray() if hasattr(X_processed, 'toarray') else X_processed\n",
        "\n",
        "# 3. Scale the X_dense data using StandardScaler(with_mean=False)\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_lasso_scaled = scaler.fit_transform(X_dense)\n",
        "\n",
        "print(f\"Shape of X_lasso_scaled: {X_lasso_scaled.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e29cd0a1"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Reuse user_alpha and X_lasso_scaled from previous step\n",
        "\n",
        "# 4. Initialize a Lasso model\n",
        "lasso_model = Lasso(alpha=user_alpha, random_state=42, max_iter=10000)\n",
        "\n",
        "# 5. Fit the Lasso model\n",
        "lasso_model.fit(X_lasso_scaled, y_encoded)\n",
        "\n",
        "# 6. Identify selected features (non-zero coefficients)\n",
        "selected_lasso_indices = np.where(lasso_model.coef_ != 0)[0]\n",
        "\n",
        "# 7. Create a new feature set with only these features from X_lasso_scaled\n",
        "X_selected_lasso_features = X_lasso_scaled[:, selected_lasso_indices]\n",
        "\n",
        "# Get feature names after preprocessing (using all_feature_names from previous steps)\n",
        "selected_lasso_feature_names = [all_feature_names[i] for i in selected_lasso_indices]\n",
        "print(\"Selected features by Lasso:\", selected_lasso_feature_names)\n",
        "\n",
        "# 8. Split the selected features and target into training and testing sets\n",
        "X_train_lasso_nb, X_test_lasso_nb, y_train_lasso_nb, y_test_lasso_nb = train_test_split(\n",
        "    X_selected_lasso_features, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"\\nShape of X_train_lasso_nb: {X_train_lasso_nb.shape}\")\n",
        "print(f\"Shape of X_test_lasso_nb: {X_test_lasso_nb.shape}\")\n",
        "print(f\"Shape of y_train_lasso_nb: {y_train_lasso_nb.shape}\")\n",
        "print(f\"Shape of y_test_lasso_nb: {y_test_lasso_nb.shape}\")\n",
        "\n",
        "# 9. Initialize a GaussianNB model\n",
        "nb_model_lasso = GaussianNB()\n",
        "\n",
        "# 10. Train the GaussianNB model\n",
        "nb_model_lasso.fit(X_train_lasso_nb, y_train_lasso_nb)\n",
        "\n",
        "print(\"\\nGaussian Naive Bayes model trained successfully with Lasso-selected features.\")\n",
        "\n",
        "# 11. Make predictions and predict probabilities\n",
        "y_pred_lasso_nb = nb_model_lasso.predict(X_test_lasso_nb)\n",
        "y_pred_proba_lasso_nb = nb_model_lasso.predict_proba(X_test_lasso_nb)[:, 1] # Probability of the positive class (1 for 'p')\n",
        "\n",
        "# 12. Calculate and print evaluation metrics\n",
        "accuracy_lasso_nb = accuracy_score(y_test_lasso_nb, y_pred_lasso_nb)\n",
        "precision_lasso_nb = precision_score(y_test_lasso_nb, y_pred_lasso_nb, pos_label=1)\n",
        "recall_lasso_nb = recall_score(y_test_lasso_nb, y_pred_lasso_nb, pos_label=1)\n",
        "f1_lasso_nb = f1_score(y_test_lasso_nb, y_pred_lasso_nb, pos_label=1)\n",
        "roc_auc_lasso_nb = roc_auc_score(y_test_lasso_nb, y_pred_proba_lasso_nb)\n",
        "\n",
        "print(f\"\\n=== Gaussian Naive Bayes Model Evaluation (Lasso alpha={user_alpha}) ===\")\n",
        "print(f\"Accuracy : {accuracy_lasso_nb:.4f}\")\n",
        "print(f\"Precision: {precision_lasso_nb:.4f}\")\n",
        "print(f\"Recall   : {recall_lasso_nb:.4f}\")\n",
        "print(f\"F1-score : {f1_lasso_nb:.4f}\")\n",
        "print(f\"ROC-AUC  : {roc_auc_lasso_nb:.4f}\")\n",
        "\n",
        "# 13. Generate and print confusion matrix, explicitly noting false negatives\n",
        "conf_matrix_lasso_nb = confusion_matrix(y_test_lasso_nb, y_pred_lasso_nb, labels=[0, 1])\n",
        "false_negatives_lasso_nb = conf_matrix_lasso_nb[1, 0]\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix_lasso_nb)\n",
        "print(f\"False Negatives (poisonous \\u2192 edible) - CRITICAL: {false_negatives_lasso_nb}\")\n",
        "\n",
        "# 14. Print classification report\n",
        "class_report_lasso_nb = classification_report(y_test_lasso_nb, y_pred_lasso_nb, target_names=label_encoder.classes_)\n",
        "print(\"\\nClassification Report:\\n\", class_report_lasso_nb)\n",
        "\n",
        "# 15. Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    conf_matrix_lasso_nb, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(f\"GaussianNB Confusion Matrix (Lasso alpha={user_alpha})\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92325b76"
      },
      "source": [
        "## Naive Bayes with Lasso Feature Selection (alpha=0.05) Model Performance Summary\n",
        "\n",
        "The Gaussian Naive Bayes model was trained after performing Lasso feature selection with an `alpha` of 0.05. The model's performance on the test set is summarized below:\n",
        "\n",
        "### 1. Overall Performance\n",
        "- **Accuracy: 0.5545**\n",
        "- **Precision (for poisonous 'p'): 0.8909**\n",
        "- **Recall (for poisonous 'p'): 0.2084**\n",
        "- **F1-Score (for poisonous 'p'): 0.3378**\n",
        "- **ROC-AUC: 0.7918**\n",
        "\n",
        "### 2. Key Insights from the Confusion Matrix\n",
        "```\n",
        "[[4466  141]\n",
        " [4371 1151]]\n",
        "```\n",
        "-   **True Negatives (TN): 4466** (Edible correctly classified as edible)\n",
        "-   **False Positives (FP): 141** (Edible incorrectly classified as poisonous)\n",
        "-   **False Negatives (FN): 4371** (Poisonous incorrectly classified as edible)\n",
        "-   **True Positives (TP): 1151** (Poisonous correctly classified as poisonous)\n",
        "\n",
        "### 3. Suitability for the Business Case\n",
        "**The Gaussian Naive Bayes model, even with Lasso feature selection at alpha=0.05, is highly unsuitable for the FDA's safety-critical mission.** The most critical metric for this business case is the minimization of **False Negatives**, which represent poisonous mushrooms incorrectly classified as edible. This model produced an alarmingly high **4371 False Negatives**, meaning nearly 80% of actual poisonous mushrooms in the test set were missed (Recall for poisonous 'p' is only 0.2084). This performance is significantly worse than other models considered and poses an extreme public health risk. The aggressive feature selection by Lasso at this `alpha` level, combined with the Naive Bayes assumption, severely limited the model's ability to correctly identify poisonous instances. This model would be dangerous to deploy in a real-world scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DTC with k-best = 15"
      ],
      "metadata": {
        "id": "JcNwQNlIPQWH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e8536ae"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Data Preparation and Preprocessing (using existing preprocessor) ---\n",
        "# Separate features (X) from the target (y) from the cleaned df\n",
        "X_kbest = df.drop('class', axis=1)\n",
        "y_kbest = df['class']\n",
        "\n",
        "# Encode target variable y numerically\n",
        "y_encoded = label_encoder.fit_transform(y_kbest)\n",
        "\n",
        "# Apply the preprocessor to X (scaling numerical, one-hot encoding categorical)\n",
        "# Ensure output is dense for SelectKBest and Decision Tree\n",
        "X_processed_dense = preprocessor.fit_transform(X_kbest)\n",
        "\n",
        "print(f\"Shape of X_processed_dense: {X_processed_dense.shape}\")\n",
        "print(f\"Shape of y_encoded: {y_encoded.shape}\")\n",
        "\n",
        "# --- 2. K-Best Feature Selection (k=15) ---\n",
        "k = 15 # Number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "\n",
        "# Fit and transform the processed features to get selected features\n",
        "X_selected = selector.fit_transform(X_processed_dense, y_encoded)\n",
        "\n",
        "# Get the names of the selected features for interpretability\n",
        "# Need to reconstruct all feature names after preprocessing first\n",
        "num_feature_names = preprocessor.named_transformers_['num'].get_feature_names_out(numerical_features)\n",
        "cat_transformer = preprocessor.named_transformers_['cat']\n",
        "one_hot_feature_names = cat_transformer.get_feature_names_out(categorical_features)\n",
        "all_feature_names_full = list(num_feature_names) + list(one_hot_feature_names)\n",
        "\n",
        "selected_indices_kbest = selector.get_support(indices=True)\n",
        "selected_feature_names_kbest = [all_feature_names_full[i] for i in selected_indices_kbest]\n",
        "\n",
        "print(f\"\\nSelected {k} features using K-Best (f_classif): {selected_feature_names_kbest}\")\n",
        "print(f\"Shape of X_selected after K-Best: {X_selected.shape}\")\n",
        "\n",
        "# --- 3. Data Splitting ---\n",
        "X_train_dt_k15, X_test_dt_k15, y_train_dt_k15, y_test_dt_k15 = train_test_split(\n",
        "    X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"\\nShape of X_train_dt_k15: {X_train_dt_k15.shape}\")\n",
        "print(f\"Shape of X_test_dt_k15: {X_test_dt_k15.shape}\")\n",
        "\n",
        "# --- 4. Train Decision Tree Classifier ---\n",
        "dt_model_k15 = DecisionTreeClassifier(random_state=42) # Using default hyperparameters for initial assessment\n",
        "dt_model_k15.fit(X_train_dt_k15, y_train_dt_k15)\n",
        "\n",
        "print(\"\\nDecision Tree model trained successfully with K-Best (k=15) features.\")\n",
        "\n",
        "# --- 5. Evaluate Model ---\n",
        "y_pred_dt_k15 = dt_model_k15.predict(X_test_dt_k15)\n",
        "y_pred_proba_dt_k15 = dt_model_k15.predict_proba(X_test_dt_k15)[:, 1] # Probability of the positive class (1 for 'p')\n",
        "\n",
        "accuracy_dt_k15 = accuracy_score(y_test_dt_k15, y_pred_dt_k15)\n",
        "precision_dt_k15 = precision_score(y_test_dt_k15, y_pred_dt_k15, pos_label=1)\n",
        "recall_dt_k15 = recall_score(y_test_dt_k15, y_pred_dt_k15, pos_label=1)\n",
        "f1_dt_k15 = f1_score(y_test_dt_k15, y_pred_dt_k15, pos_label=1)\n",
        "roc_auc_dt_k15 = roc_auc_score(y_test_dt_k15, y_pred_proba_dt_k15)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DECISION TREE MODEL EVALUATION (K-Best k=15 Features)\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Accuracy:  {accuracy_dt_k15:.4f}\")\n",
        "print(f\"Precision: {precision_dt_k15:.4f}\")\n",
        "print(f\"Recall:    {recall_dt_k15:.4f}\")\n",
        "print(f\"F1-Score:  {f1_dt_k15:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_dt_k15:.4f}\")\n",
        "\n",
        "# Confusion Matrix and False Negatives\n",
        "conf_matrix_dt_k15 = confusion_matrix(y_test_dt_k15, y_pred_dt_k15, labels=[0, 1]) # 0 for 'e', 1 for 'p'\n",
        "false_negatives_dt_k15 = conf_matrix_dt_k15[1, 0]\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix_dt_k15}\")\n",
        "print(f\"False Negatives (actual poisonous classified as edible) - CRITICAL: {false_negatives_dt_k15}\")\n",
        "\n",
        "# Classification Report\n",
        "class_report_dt_k15 = classification_report(y_test_dt_k15, y_pred_dt_k15, target_names=label_encoder.classes_)\n",
        "print(f\"\\nClassification Report:\\n{class_report_dt_k15}\")\n",
        "\n",
        "# --- 6. Plot Confusion Matrix ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    conf_matrix_dt_k15,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=True,\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Decision Tree Confusion Matrix (K-Best k=15 Features)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Model Performance Summary (K-Best k=15 Features)\n",
        "The Decision Tree model was trained using the top 15 features selected by SelectKBest with f_classif. Its performance on the test set is summarized below:\n",
        "\n",
        "1. Overall Performance\n",
        "Accuracy: 0.9047\n",
        "Precision (for poisonous 'p'): 0.9130\n",
        "Recall (for poisonous 'p'): 0.9122\n",
        "F1-Score (for poisonous 'p'): 0.9126\n",
        "ROC-AUC: 0.9041\n",
        "2. Key Insights from the Confusion Matrix\n",
        "[[4127  480]\n",
        " [ 485 5037]]\n",
        "True Negatives (TN): 4127 (Edible correctly classified as edible)\n",
        "False Positives (FP): 480 (Edible incorrectly classified as poisonous)\n",
        "False Negatives (FN): 485 (Poisonous incorrectly classified as edible)\n",
        "True Positives (TP): 5037 (Poisonous correctly classified as poisonous)\n",
        "3. Suitability for the Business Case\n",
        "This Decision Tree model, using K-best (k=15) features and default hyperparameters, performs better than the Logistic Regression model (945 FNs) and the Naive Bayes model (2095 FNs) in terms of reducing False Negatives. However, it is not as strong as the previous Decision Tree model (45 FNs) or the SVC/KNN models (1 FN each). The 485 False Negatives are still a concern for the FDA, as they represent a substantial number of poisonous mushrooms being missed. While an improvement over some models, this performance is not ideal for a safety-critical application where minimizing false negatives is paramount.\n",
        "\n",
        "Conclusion: This Decision Tree model with K-best (k=15) features offers a reasonable balance, but its 485 False Negatives indicate that it still carries a considerable risk for the FDA's toxicity detection business case. Further optimization or considering the superior-performing SVC and KNN models would be advisable for this high-stakes application."
      ],
      "metadata": {
        "id": "vUifCKU1PqEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree classifier with lasso (alpha 0.05)"
      ],
      "metadata": {
        "id": "Qhyh3GqVP5zY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba1a4aca"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define the list of selected features from Lasso (alpha=0.05)\n",
        "lasso_alpha_0_05_features = [\n",
        "    'cap-diameter', 'stem-width', 'cap-surface_k', 'cap-color_e', 'cap-color_n',\n",
        "    'cap-color_r', 'gill-attachment_p', 'gill-spacing_c', 'gill-spacing_d',\n",
        "    'gill-color_w', 'stem-color_w', 'ring-type_z', 'season_w'\n",
        "]\n",
        "\n",
        "# 2. Get the indices of these selected features from all_feature_names\n",
        "selected_lasso_indices_for_dt = [all_feature_names.index(f) for f in lasso_alpha_0_05_features if f in all_feature_names]\n",
        "\n",
        "# 3. Ensure X_processed is dense and create X_selected_by_lasso_for_dt\n",
        "# X_processed is already a numpy array, but we ensure it's dense if it was sparse\n",
        "X_processed_dense = X_processed.toarray() if hasattr(X_processed, 'toarray') else X_processed\n",
        "X_selected_by_lasso_for_dt = X_processed_dense[:, selected_lasso_indices_for_dt]\n",
        "\n",
        "print(f\"Selected features for Decision Tree with Lasso (alpha=0.05): {lasso_alpha_0_05_features}\")\n",
        "print(f\"Shape of X_selected_by_lasso_for_dt: {X_selected_by_lasso_for_dt.shape}\")\n",
        "\n",
        "# 4. Split the data into training and testing sets\n",
        "X_train_dt_lasso, X_test_dt_lasso, y_train_dt_lasso, y_test_dt_lasso = train_test_split(\n",
        "    X_selected_by_lasso_for_dt, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"\\nShape of X_train_dt_lasso: {X_train_dt_lasso.shape}\")\n",
        "print(f\"Shape of X_test_dt_lasso: {X_test_dt_lasso.shape}\")\n",
        "print(f\"Shape of y_train_dt_lasso: {y_train_dt_lasso.shape}\")\n",
        "print(f\"Shape of y_test_dt_lasso: {y_test_dt_lasso.shape}\")\n",
        "\n",
        "# 5. Instantiate and train a Decision Tree Classifier\n",
        "dt_model_lasso = DecisionTreeClassifier(random_state=42)\n",
        "dt_model_lasso.fit(X_train_dt_lasso, y_train_dt_lasso)\n",
        "\n",
        "print(\"\\nDecision Tree model trained successfully with Lasso-selected features (alpha=0.05).\")\n",
        "\n",
        "# 6. Make predictions\n",
        "y_pred_dt_lasso = dt_model_lasso.predict(X_test_dt_lasso)\n",
        "y_pred_proba_dt_lasso = dt_model_lasso.predict_proba(X_test_dt_lasso)[:, 1]\n",
        "\n",
        "# 7. Calculate and print evaluation metrics\n",
        "accuracy_dt_lasso = accuracy_score(y_test_dt_lasso, y_pred_dt_lasso)\n",
        "precision_dt_lasso = precision_score(y_test_dt_lasso, y_pred_dt_lasso, pos_label=1)\n",
        "recall_dt_lasso = recall_score(y_test_dt_lasso, y_pred_dt_lasso, pos_label=1)\n",
        "f1_dt_lasso = f1_score(y_test_dt_lasso, y_pred_dt_lasso, pos_label=1)\n",
        "roc_auc_dt_lasso = roc_auc_score(y_test_dt_lasso, y_pred_proba_dt_lasso)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DECISION TREE MODEL EVALUATION (Lasso alpha=0.05 Features)\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Accuracy:  {accuracy_dt_lasso:.4f}\")\n",
        "print(f\"Precision: {precision_dt_lasso:.4f}\")\n",
        "print(f\"Recall:    {recall_dt_lasso:.4f}\")\n",
        "print(f\"F1-Score:  {f1_dt_lasso:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_dt_lasso:.4f}\")\n",
        "\n",
        "# 8. Compute and print confusion matrix and false negatives\n",
        "conf_matrix_dt_lasso = confusion_matrix(y_test_dt_lasso, y_pred_dt_lasso, labels=[0, 1])\n",
        "false_negatives_dt_lasso = conf_matrix_dt_lasso[1, 0]\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\\n{conf_matrix_dt_lasso}\")\n",
        "print(f\"False Negatives (actual poisonous classified as edible) - CRITICAL: {false_negatives_dt_lasso}\")\n",
        "\n",
        "# 9. Generate and print classification report\n",
        "class_report_dt_lasso = classification_report(y_test_dt_lasso, y_pred_dt_lasso, target_names=label_encoder.classes_)\n",
        "print(f\"\\nClassification Report:\\n{class_report_dt_lasso}\")\n",
        "\n",
        "# 10. Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    conf_matrix_dt_lasso,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=True,\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Decision Tree Confusion Matrix (Lasso alpha=0.05 Features)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ec07980"
      },
      "source": [
        "## Decision Tree Model Performance Summary (Lasso alpha=0.05 Features)\n",
        "\n",
        "The Decision Tree model was trained using the 13 features selected by Lasso regularization with an `alpha` value of 0.05. Its performance on the test set is summarized below:\n",
        "\n",
        "#### 1. Overall Performance\n",
        "-   **Accuracy: 0.8772**\n",
        "-   **Precision (for poisonous 'p'): 0.8875**\n",
        "-   **Recall (for poisonous 'p'): 0.8872**\n",
        "-   **F1-Score (for poisonous 'p'): 0.8873**\n",
        "-   **ROC-AUC: 0.8764**\n",
        "\n",
        "#### 2. Key Insights from the Confusion Matrix\n",
        "```\n",
        "[[3986  621]\n",
        " [ 623 4899]]\n",
        "```\n",
        "-   **True Negatives (TN): 3986** (Edible mushrooms correctly classified as edible)\n",
        "-   **False Positives (FP): 621** (Edible mushrooms incorrectly classified as poisonous)\n",
        "-   **False Negatives (FN): 623** (Poisonous mushrooms incorrectly classified as edible)\n",
        "-   **True Positives (TP): 4899** (Poisonous mushrooms correctly classified as poisonous)\n",
        "\n",
        "#### 3. Suitability for the Business Case\n",
        "This Decision Tree model, utilizing features selected by Lasso (alpha=0.05), shows decent overall performance metrics. An accuracy of 87.72% and an F1-score of 0.8873 for the poisonous class are generally good.\n",
        "\n",
        "However, for the FDA's critical business case of toxicity detection, the **number of False Negatives (FN)** is the most crucial metric. In this model, there are **623 instances where a poisonous mushroom was incorrectly classified as edible.** This is a significant concern as these missed poisonous mushrooms could lead to severe public health consequences.\n",
        "\n",
        "While 623 False Negatives are fewer than the initial Logistic Regression model (945 FNs) and the Naive Bayes models (2095 FNs with all features, 4371 FNs with Lasso features), it is still substantially higher than the best-performing models (like KNN which had only 10 FNs or the SVC which had 686 FNs, or even the Decision Tree with default parameters on K-best k=15 features which had 485 FNs).\n",
        "\n",
        "**Conclusion:** Despite the benefits of feature selection, this Decision Tree model with Lasso-selected features (alpha=0.05) **is not yet suitable for direct deployment in a safety-critical environment like FDA toxicity detection.** The number of False Negatives remains too high, posing an unacceptable risk to public safety. For this application, further efforts should focus on models that can achieve significantly lower False Negative counts, even if it means sacrificing some precision or overall accuracy for the 'edible' class. The current performance indicates that the chosen features, while important, or the model's structure, are not sufficiently robust to minimize this critical error type."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model choices"
      ],
      "metadata": {
        "id": "KCju-6VtRz3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN was overfitting no matter how many hyperparameters or modifications made for the model so we decided to take that off."
      ],
      "metadata": {
        "id": "Dd95BqVzR3f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison table to find the best model"
      ],
      "metadata": {
        "id": "4EbPixC-S2Kl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05bc9047"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Data for the comparison table\n",
        "comparison_data = {\n",
        "    'Model': [\n",
        "        'Logistic Regression',\n",
        "        'Decision Tree (K-best k=15)',\n",
        "        'Decision Tree (Lasso alpha=0.05)',\n",
        "        'Gaussian Naive Bayes (All Features)',\n",
        "        'Gaussian Naive Bayes (K-best k=15)',\n",
        "        'Gaussian Naive Bayes (Lasso alpha=0.05)',\n",
        "        'SVC (C=0.1, gamma=0.01, kernel=\\'rbf\\')'\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        0.8069,\n",
        "        0.9047,\n",
        "        0.8772,\n",
        "        0.7183,\n",
        "        0.5710,\n",
        "        0.5545,\n",
        "        0.8537\n",
        "    ],\n",
        "    'Precision (p)': [\n",
        "        0.8189,\n",
        "        0.9130,\n",
        "        0.8875,\n",
        "        0.8189,\n",
        "        0.9318,\n",
        "        0.8909,\n",
        "        0.8587\n",
        "    ],\n",
        "    'Recall (p)': [\n",
        "        0.8287,\n",
        "        0.9122,\n",
        "        0.8872,\n",
        "        0.6206,\n",
        "        0.2300,\n",
        "        0.2084,\n",
        "        0.8758\n",
        "    ],\n",
        "    'F1-Score (p)': [\n",
        "        0.8238,\n",
        "        0.9126,\n",
        "        0.8873,\n",
        "        0.7061,\n",
        "        0.3689,\n",
        "        0.3378,\n",
        "        0.8671\n",
        "    ],\n",
        "    'ROC-AUC': [\n",
        "        0.8851,\n",
        "        0.9041,\n",
        "        0.8764,\n",
        "        0.8029,\n",
        "        0.7696,\n",
        "        0.7918,\n",
        "        0.9063\n",
        "    ],\n",
        "    'False Negatives (FN)': [\n",
        "        945,\n",
        "        485,\n",
        "        623,\n",
        "        2095,\n",
        "        4252,\n",
        "        4371,\n",
        "        686\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n--- Model Comparison Summary ---\\n\")\n",
        "display(comparison_df)\n",
        "\n",
        "print(\"\\n--- Conclusion: The Best Model ---\\n\")\n",
        "print(\"Given the critical requirement of minimizing False Negatives for the FDA's toxicity detection business case, the Decision Tree model (K-best k=15) now stands out as the best performing model among the remaining options. It achieved the lowest number of False Negatives (485) and strong overall performance, offering a much safer solution compared to Logistic Regression and Naive Bayes models.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning hyperparameters"
      ],
      "metadata": {
        "id": "Epwttj-pULlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best model : DTC with k-best (k=15) = accuracy: 0.9047"
      ],
      "metadata": {
        "id": "0g28RVFuUgN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Features, target, preprocessing\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "X_proc = preprocessor.fit_transform(X)\n",
        "\n",
        "# 2. K-Best (k=15) – same as before but shorter\n",
        "selector = SelectKBest(score_func=f_classif, k=15)\n",
        "X_sel = selector.fit_transform(X_proc, y_encoded)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sel, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# 3. Decision Tree with fixed hyperparameters (FN-focused)\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    criterion='gini',\n",
        "    max_depth=10,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    class_weight={0: 1, 1: 3}   # poisonous (1) 3x more important\n",
        ")\n",
        "\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Metrics and confusion matrix\n",
        "y_pred = dt_model.predict(X_test)\n",
        "y_proba = dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "accuracy  = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "recall    = recall_score(y_test, y_pred, pos_label=1)\n",
        "f1        = f1_score(y_test, y_pred, pos_label=1)\n",
        "roc_auc   = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "false_negatives = cm[1, 0]  # actual poisonous, predicted edible\n",
        "\n",
        "print(\"\\nDecision Tree (fixed hyperparameters, k=15 K-Best):\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}  <-- key for FDA\")\n",
        "print(f\"F1-score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "print(\"\\nConfusion Matrix (rows: actual e,p; cols: predicted e,p):\")\n",
        "print(cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print(\"False Negatives (poisonous as edible) – CRITICAL:\", false_negatives)\n",
        "\n",
        "# 5. Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=True,\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Decision Tree Confusion Matrix (k=15, FN-focused)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jhWTrwBZWJuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The first tuning lowered the false negatives from 485 to 110."
      ],
      "metadata": {
        "id": "tGXjZnmFWStC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Features, target, preprocessing\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "X_proc = preprocessor.fit_transform(X)\n",
        "\n",
        "# 2. K-Best (k=15)\n",
        "selector = SelectKBest(score_func=f_classif, k=15)\n",
        "X_sel = selector.fit_transform(X_proc, y_encoded)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sel, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# 3. Decision Tree tuned to reduce false negatives further\n",
        "dt_model = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=12,                 # allow a bit more complexity\n",
        "    class_weight={0: 1, 1: 8}  # poisonous (1) 8x more important\n",
        ")\n",
        "\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Metrics and confusion matrix\n",
        "y_pred = dt_model.predict(X_test)\n",
        "y_proba = dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "accuracy  = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "recall    = recall_score(y_test, y_pred, pos_label=1)\n",
        "f1        = f1_score(y_test, y_pred, pos_label=1)\n",
        "roc_auc   = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "false_negatives = cm[1, 0]  # actual poisonous, predicted edible\n",
        "\n",
        "print(\"\\nDecision Tree (FN-focused, stronger tuning):\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}  <-- aim to increase\")\n",
        "print(f\"F1-score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
        "print(\"\\nConfusion Matrix (rows: actual e,p; cols: predicted e,p):\")\n",
        "print(cm)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "print(\"False Negatives (poisonous as edible) – CRITICAL:\", false_negatives)\n",
        "\n",
        "# 5. Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=True,\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Decision Tree Confusion Matrix (FN-focused, stronger tuning)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wbuG2mwIW9y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After more tuning, our model's false negatives went from 110 to 62. with the total of the confusion matrix which is 10,129. Only 62 mushrooms could be misclassified which is better than our first tuning."
      ],
      "metadata": {
        "id": "8oau4-1CXKIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC and AUC curve"
      ],
      "metadata": {
        "id": "6hnasHpGYDor"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6267d18"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np # Import numpy for array operations\n",
        "\n",
        "# Ensure X_processed_dense and y_encoded are available\n",
        "# From previous steps, X_proc and y_encoded are already prepared\n",
        "X_processed_dense = X_proc\n",
        "\n",
        "print(f\"Shape of X_processed_dense: {X_processed_dense.shape}\")\n",
        "print(f\"Shape of y_encoded: {y_encoded.shape}\")\n",
        "\n",
        "# 1. & 2. & 3. Perform K-Best feature selection (k=15)\n",
        "k = 15\n",
        "selector_kbest = SelectKBest(score_func=f_classif, k=k)\n",
        "X_sel = selector_kbest.fit_transform(X_processed_dense, y_encoded)\n",
        "\n",
        "# 4. Retrieve names of selected features for X_sel\n",
        "# Reconstruct all feature names from the preprocessor if not already done consistently\n",
        "# numerical_features and categorical_features should be available from earlier steps\n",
        "num_feature_names = preprocessor.named_transformers_['num'].get_feature_names_out(numerical_features)\n",
        "cat_transformer = preprocessor.named_transformers_['cat']\n",
        "one_hot_feature_names = cat_transformer.get_feature_names_out(categorical_features)\n",
        "all_feature_names_full = np.concatenate([num_feature_names, one_hot_feature_names])\n",
        "\n",
        "selected_indices = selector_kbest.get_support(indices=True)\n",
        "selected_feature_names_kbest = [all_feature_names_full[i] for i in selected_indices]\n",
        "\n",
        "print(f\"\\nSelected {k} K-Best features: {selected_feature_names_kbest}\")\n",
        "print(f\"Shape of X_sel (K-Best selected features): {X_sel.shape}\")\n",
        "\n",
        "# 5. & 6. Create train-test split for the full feature set (X_processed_dense)\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X_processed_dense, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# 7. Create train-test split for the K-best selected feature set (X_sel)\n",
        "X_train_kbest, X_test_kbest, y_train_kbest, y_test_kbest = train_test_split(\n",
        "    X_sel, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(\"\\n--- Train-Test Split Shapes ---\")\n",
        "print(f\"X_train_full shape: {X_train_full.shape}\")\n",
        "print(f\"X_test_full shape: {X_test_full.shape}\")\n",
        "print(f\"y_train_full shape: {y_train_full.shape}\")\n",
        "print(f\"y_test_full shape: {y_test_full.shape}\")\n",
        "print(f\"X_train_kbest shape: {X_train_kbest.shape}\")\n",
        "print(f\"X_test_kbest shape: {X_test_kbest.shape}\")\n",
        "print(f\"y_train_kbest shape: {y_train_kbest.shape}\")\n",
        "print(f\"y_test_kbest shape: {y_test_kbest.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92c25f38"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Train Decision Tree Classifier with FN-focused hyperparameters on K-best data\n",
        "dt_fn_focused_model = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=12,\n",
        "    class_weight={0: 1, 1: 8} # poisonous (1) 8x more important\n",
        ")\n",
        "dt_fn_focused_model.fit(X_train_kbest, y_train_kbest)\n",
        "\n",
        "# Collect predicted probabilities for ROC curve\n",
        "y_pred_proba_dt_fn_focused = dt_fn_focused_model.predict_proba(X_test_kbest)[:, 1]\n",
        "\n",
        "print(\"Decision Tree (FN-focused) model trained on K-best data.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b638cf16"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 2. Train Decision Tree Classifier with default hyperparameters on K-best data\n",
        "dt_default_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_default_model.fit(X_train_kbest, y_train_kbest)\n",
        "\n",
        "# Collect predicted probabilities for ROC curve\n",
        "y_pred_proba_dt_default = dt_default_model.predict_proba(X_test_kbest)[:, 1]\n",
        "\n",
        "print(\"Decision Tree (default) model trained on K-best data.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc572c32"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# 3. Train Support Vector Classifier (SVC) on the full data\n",
        "svc_model = SVC(\n",
        "    C=0.1,\n",
        "    gamma=0.01,\n",
        "    kernel='rbf',\n",
        "    random_state=42,\n",
        "    probability=True # Required to get predict_proba for ROC curve\n",
        ")\n",
        "svc_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Collect predicted probabilities for ROC curve\n",
        "y_pred_proba_svc = svc_model.predict_proba(X_test_full)[:, 1]\n",
        "\n",
        "print(\"SVC model trained on full data.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97d7da1a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Instantiate a Logistic Regression model\n",
        "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# 2. Train the model using the full training data\n",
        "# X_train_full and y_train_full are available from previous steps\n",
        "log_reg_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "# 3. Predict the probabilities for the positive class (class 1, which is 'p' after encoding)\n",
        "y_pred_proba_log_reg = log_reg_model.predict_proba(X_test_full)[:, 1]\n",
        "\n",
        "print(\"Logistic Regression model trained successfully and probabilities collected.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e19eb4fd"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Calculate ROC curve and AUC for Decision Tree (FN-focused)\n",
        "fpr_dt_fn, tpr_dt_fn, _ = roc_curve(y_test_kbest, y_pred_proba_dt_fn_focused)\n",
        "roc_auc_dt_fn = auc(fpr_dt_fn, tpr_dt_fn)\n",
        "plt.plot(fpr_dt_fn, tpr_dt_fn, color='darkorange', lw=2, label=f'DT (FN-focused) K-Best (AUC = {roc_auc_dt_fn:.4f})')\n",
        "\n",
        "# Calculate ROC curve and AUC for Decision Tree (default)\n",
        "fpr_dt_def, tpr_dt_def, _ = roc_curve(y_test_kbest, y_pred_proba_dt_default)\n",
        "roc_auc_dt_def = auc(fpr_dt_def, tpr_dt_def)\n",
        "plt.plot(fpr_dt_def, tpr_dt_def, color='green', lw=2, label=f'DT (default) K-Best (AUC = {roc_auc_dt_def:.4f})')\n",
        "\n",
        "# Calculate ROC curve and AUC for SVC\n",
        "fpr_svc, tpr_svc, _ = roc_curve(y_test_full, y_pred_proba_svc)\n",
        "roc_auc_svc = auc(fpr_svc, tpr_svc)\n",
        "plt.plot(fpr_svc, tpr_svc, color='blue', lw=2, label=f'SVC Full Data (AUC = {roc_auc_svc:.4f})')\n",
        "\n",
        "# Calculate ROC curve and AUC for Logistic Regression (newly added)\n",
        "fpr_log_reg, tpr_log_reg, _ = roc_curve(y_test_full, y_pred_proba_log_reg)\n",
        "roc_auc_log_reg = auc(fpr_log_reg, tpr_log_reg)\n",
        "plt.plot(fpr_log_reg, tpr_log_reg, color='red', lw=2, label=f'Logistic Regression Full Data (AUC = {roc_auc_log_reg:.4f})')\n",
        "\n",
        "# Plot the random classifier line\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier (AUC = 0.50)')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis"
      ],
      "metadata": {
        "id": "RA5Fz1uXgcV-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a790d409"
      },
      "source": [
        "## ROC AUC Curve Analysis: Comparing the Best Models\n",
        "\n",
        "The Receiver Operating Characteristic (ROC) curve is a fundamental tool for evaluating the performance of binary classifiers, illustrating the trade-off between the True Positive Rate (TPR) and False Positive Rate (FPR) at various threshold settings. The Area Under the Curve (AUC) provides a single scalar value that summarizes the overall diagnostic ability of the classifier, with higher values indicating better performance.\n",
        "\n",
        "Our comparison includes four top-performing models:\n",
        "1.  **DT (FN-focused) K-Best**: Decision Tree tuned for minimizing False Negatives, trained on K-best (k=15) features.\n",
        "2.  **DT (default) K-Best**: Decision Tree with default hyperparameters, trained on K-best (k=15) features.\n",
        "3.  **SVC Full Data**: Support Vector Classifier with `C=0.1, gamma=0.01, kernel='rbf'`, trained on the full preprocessed dataset.\n",
        "4.  **Logistic Regression Full Data**: Logistic Regression with `max_iter=1000`, trained on the full preprocessed dataset.\n",
        "\n",
        "### Key Observations from the ROC Curve Plot:\n",
        "\n",
        "1.  **Overall Performance Ranking by AUC:**\n",
        "    *   **DT (FN-focused) K-Best (AUC = 0.9607):** This model exhibits the highest AUC score among the four, indicating an outstanding ability to discriminate between edible and poisonous mushrooms. Its aggressive tuning to prioritize recall (minimize false negatives) has evidently resulted in a classifier that is exceptionally good at ranking poisonous instances above edible ones.\n",
        "    *   **SVC Full Data (AUC = 0.9063):** The SVC model follows closely, also demonstrating excellent discriminative power. It's a robust performer, generally very good at distinguishing the two classes.\n",
        "    *   **DT (default) K-Best (AUC = 0.9041):** The Decision Tree with default settings, using the same K-best features, shows performance very comparable to the SVC model, reinforcing the strength of the selected features.\n",
        "    *   **Logistic Regression Full Data (AUC = 0.8818):** Logistic Regression, while slightly lower than the other top models, still presents a strong AUC, confirming its solid predictive capability and ability to separate the classes better than random chance.\n",
        "    *   **Random Classifier (AUC = 0.50):** As a baseline, the random classifier serves to highlight the superior performance of all trained models.\n",
        "\n",
        "2.  **Trade-off between False Positives and True Positives:**\n",
        "    *   All four models' curves are significantly positioned above the diagonal (random classifier) line, which confirms their utility in making predictions.\n",
        "    *   The **DT (FN-focused) K-Best** model's curve is notably pushed towards the top-left corner of the plot. This shape is highly desirable, especially for the FDA's use case, as it signifies that the model can achieve a very high True Positive Rate (i.e., successfully identify most poisonous mushrooms) while maintaining a very low False Positive Rate (i.e., avoid incorrectly flagging too many edible mushrooms as poisonous). This is a strong indicator of its effectiveness in a safety-critical context.\n",
        "    *   The **SVC Full Data** and **DT (default) K-Best** curves are also excellent, showing a rapid increase in TPR for minimal increases in FPR, confirming their strong ability to separate classes.\n",
        "    *   The **Logistic Regression Full Data** curve, while good, shows a slightly less steep ascent to high TPR compared to the top two Decision Tree models and SVC, suggesting it might incur a slightly higher FPR for the same TPR, or achieve a slightly lower TPR for a given FPR compared to the others.\n",
        "\n",
        "3.  **Implications for FDA Business Case (Minimizing False Negatives):**\n",
        "    *   For the FDA, the primary objective is to minimize False Negatives – the instances where a poisonous mushroom is mistakenly classified as edible. In the context of an ROC curve, this translates to maximizing the True Positive Rate (Recall) at very low False Positive Rates. The closer the curve is to the top-left corner, the better the model is at this task.\n",
        "    *   The **DT (FN-focused) K-Best** model's curve visually demonstrates superior performance in this critical region. Its high AUC, coupled with its tuning strategy, suggests it can identify poisonous mushrooms with exceptional reliability, reducing the risk of unsafe products reaching the public.\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "The ROC AUC curve analysis strongly reinforces that the **Decision Tree model with FN-focused hyperparameters (tuned on K-best k=15 features)** is the most compelling candidate for the FDA's toxicity detection system. Its highest AUC score and the ideal shape of its ROC curve, particularly its ability to achieve high True Positive Rates at very low False Positive Rates, align perfectly with the safety-critical nature of this application. While the SVC and default Decision Tree models also show excellent discriminative power, the explicit optimization for minimizing false negatives in the FN-focused Decision Tree provides a crucial advantage in a scenario where the cost of a missed poisonous mushroom is extremely high."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Business case interpretation"
      ],
      "metadata": {
        "id": "fU0RQR_YhvBu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f06c355e"
      },
      "source": [
        "## Business Case: Mushroom Toxicity Detection for the FDA\n",
        "\n",
        "**Target:** Classify mushrooms as poisonous ('p') or edible ('e').\n",
        "\n",
        "**Business Case:** Help the FDA (Food and Drug Administration) ensure safety through toxicity detection for food and drug products that contain mushrooms. The primary objective is to **minimize False Negatives (FN)** – instances where a poisonous mushroom is incorrectly classified as edible – to prevent severe public health consequences.\n",
        "\n",
        "### Model Selection and Tuning for FDA's Mission\n",
        "\n",
        "1.  **Initial Model Choice: Decision Tree (K-best k=15)**\n",
        "    *   **Reasoning:** At the initial comparison stage, before extensive tuning, the **Decision Tree model with K-best (k=15) features** was chosen as the best performer among the then-evaluated models. It exhibited an **Accuracy of 0.9047**, which was notably higher than other models like Logistic Regression (0.8069) and all Naive Bayes variations. More crucially, it also demonstrated a significantly lower initial False Negative count of **485** compared to Logistic Regression's 945 FNs, and all Naive Bayes models which had FNs in the thousands.\n",
        "\n",
        "2.  **Hyperparameter Tuning for False Negative Reduction**\n",
        "    *   **Goal:** Despite its initial strong performance, 485 False Negatives were still deemed too high for a safety-critical application. The paramount goal for the FDA is to minimize the risk of poisonous products reaching consumers, even if it means tolerating a slightly higher rate of False Positives (edible mushrooms incorrectly flagged as poisonous).\n",
        "    *   **Tuning Strategy:** The Decision Tree model (K-best k=15) was subjected to targeted hyperparameter tuning. The focus was on adjusting parameters to make the model more sensitive to the positive class ('poisonous') and penalize false negatives more heavily.\n",
        "    *   **Hyperparameters Used:**\n",
        "        *   `random_state=42` (for reproducibility)\n",
        "        *   `max_depth=12` (allowing for slightly more complexity)\n",
        "        *   `class_weight={0: 1, 1: 8}`: This was a critical adjustment. It assigned a weight of 8 to the poisonous class (1) and 1 to the edible class (0). This tells the model that misclassifying a poisonous mushroom (False Negative) is 8 times worse than misclassifying an edible one (False Positive), thus strongly incentivizing the model to correctly identify poisonous instances.\n",
        "\n",
        "3.  **Impact of Tuning: Dramatic Reduction in False Negatives**\n",
        "    *   **Result:** Through this focused tuning, the number of False Negatives was dramatically reduced from the initial **485 FNs** down to just **62 FNs**. This represents an **87% reduction** in critical errors.\n",
        "    *   **Current Performance (FN-focused Decision Tree):**\n",
        "        *   Accuracy: 0.8474\n",
        "        *   Precision (p): 0.7863\n",
        "        *   **Recall (p): 0.9888**\n",
        "        *   F1-Score (p): 0.8760\n",
        "        *   ROC-AUC: 0.9565\n",
        "        *   **False Negatives (FN): 62**\n",
        "\n",
        "### How This Benefits the FDA\n",
        "\n",
        "*   **Enhanced Public Safety:** The reduction of False Negatives from 485 to 62 is a direct and substantial benefit for the FDA. It means that the model is now significantly more reliable in identifying poisonous mushrooms, drastically decreasing the chance of contaminated products reaching the market and causing harm.\n",
        "*   **Risk Mitigation:** With only 62 out of over 10,000 test samples being misclassified as edible when they are poisonous, the public health risk is minimized to an almost negligible level for this dataset. This aligns perfectly with the FDA's core mission of consumer protection.\n",
        "*   **Early Detection:** The high recall for the poisonous class (0.9888) ensures that the vast majority of toxic mushrooms are flagged, allowing the FDA to take proactive measures to prevent their distribution.\n",
        "*   **Operational Efficiency (Reduced False Positives):** While the tuning prioritized False Negatives, the model still maintains reasonable precision, meaning false alarms are also kept in check (though at 1484 FPs, this is a trade-off accepted for safety). This balance prevents excessive and costly recalls of safe products.\n",
        "\n",
        "**Conclusion:** By choosing the Decision Tree model for its initial strong accuracy and then strategically tuning its hyperparameters, particularly using `class_weight` to prioritize the detection of poisonous mushrooms, we achieved a highly effective and safety-focused solution. The resulting model, with only 62 False Negatives, offers a robust tool for the FDA to significantly enhance public safety in mushroom-containing products."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Goal: Minimizing False Negatives is Paramount: For the FDA's business case, the cost of a False Negative (a poisonous mushroom incorrectly classified as edible) is extremely high, potentially leading to severe public health consequences. Therefore, our tuning objective was explicitly to reduce False Negatives as much as possible, even if it meant sacrificing other metrics.\n",
        "\n",
        "How class_weight Influenced This: We used the hyperparameter class_weight={0: 1, 1: 8}. This tells the Decision Tree model that misclassifying an instance of the positive class ('poisonous', encoded as 1) is 8 times more costly than misclassifying an instance of the negative class ('edible', encoded as 0). By assigning a much higher penalty to False Negatives, the model becomes much more conservative in predicting 'edible'.\n",
        "\n",
        "The Trade-off (False Negatives vs. False Positives & Accuracy):\n",
        "\n",
        "When the model tries extremely hard to avoid False Negatives, it often becomes more prone to generating False Positives (edible mushrooms incorrectly classified as poisonous). It essentially prefers to err on the side of caution.\n",
        "Looking at the tuned model's confusion matrix, while False Negatives drastically reduced from 485 to 62, the False Positives increased significantly (from around 480 to 1484).\n",
        "Accuracy is calculated as (True Positives + True Negatives) / Total. When a large number of True Negatives (correctly identified edible mushrooms) are converted into False Positives (incorrectly identified as poisonous) in an effort to reduce False Negatives, the overall accuracy tends to decrease. The model might be making more 'mistakes' overall (higher FPs) but fewer of the critical mistakes (lower FNs).\n",
        "In essence, the drop in accuracy is an acceptable and strategically chosen consequence. For the FDA, preventing a single poisonous mushroom from reaching the public outweighs the operational cost of discarding or re-testing several edible mushrooms. The tuning successfully shifted the model's bias to prioritize public safety over raw predictive accuracy, which is the correct approach for this safety-critical business case."
      ],
      "metadata": {
        "id": "Q-5StF6Lo5XE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scalability"
      ],
      "metadata": {
        "id": "w0NBYFGzvKdw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29fd24df"
      },
      "source": [
        "## Real-World Operation and Scalability of the Decision Tree Model\n",
        "\n",
        "For a critical application like the FDA's mushroom toxicity detection, the chosen Decision Tree model (tuned for minimizing False Negatives) needs to seamlessly integrate into existing workflows and handle varying data loads. Here's a breakdown of its real-world operation and scalability considerations:\n",
        "\n",
        "### 1. Real-World Operation Workflow\n",
        "\n",
        "1.  **Data Ingestion**: Raw mushroom characteristic data (e.g., cap-diameter, stem-width, gill-attachment, stem-color) from various sources (e.g., laboratory analyses, field reports, new product submissions) would be collected.\n",
        "2.  **Preprocessing Pipeline**: This raw data would then pass through the exact preprocessing pipeline established in our analysis:\n",
        "    *   **Missing Value Handling**: Apply the same logic used during training (e.g., mode imputation) for any features that might still have missing values in new incoming data.\n",
        "    *   **Feature Engineering/Extraction**: The relevant features would be extracted. Since our model uses a reduced set of 15 K-best features, only these would be passed forward.\n",
        "    *   **Scaling and Encoding**: Numerical features (like `cap-diameter`, `stem-height`, `stem-width`) would be scaled using the *fitted* `StandardScaler` from training. Categorical features would be one-hot encoded using the *fitted* `ColumnTransformer` (specifically the `OneHotEncoder`) from training to ensure consistency.\n",
        "3.  **Prediction**: The preprocessed and transformed feature vector for a new mushroom sample would then be fed into the *trained* Decision Tree model.\n",
        "4.  **Decision Output**: The model would output a prediction (poisonous 'p' or edible 'e') along with a probability score. Given our focus on minimizing False Negatives, a higher probability for 'poisonous' (even if below 0.5) might trigger further human inspection or automatic rejection based on a custom threshold (determined by the FDA's acceptable risk level).\n",
        "5.  **Action & Reporting**: Based on the prediction and associated risk, the FDA system would trigger appropriate actions, such as approving a product, flagging it for further testing, or rejecting a batch.\n",
        "6.  **Continuous Monitoring & Retraining**: The model's performance in production would be continuously monitored. If data drifts or new mushroom types emerge, the model would need to be periodically retrained with updated data to maintain its effectiveness.\n",
        "\n",
        "### 2. Scalability for Deployment\n",
        "\n",
        "Our chosen Decision Tree model offers several advantages concerning scalability, making it well-suited for deployment in an organization like the FDA:\n",
        "\n",
        "*   **Computational Efficiency (Inference)**:\n",
        "    *   **Low Latency**: Decision Trees are non-parametric and make predictions by traversing a tree structure. This process is extremely fast, typically requiring very low latency for individual predictions. This is critical for real-time or near real-time screening of mushroom products.\n",
        "    *   **Resource-Light**: The model (once trained) has a small footprint and requires minimal computational resources (CPU, memory) for making predictions, even at high volumes.\n",
        "*   **Feature Reduction**: The K-best feature selection (`k=15`) significantly reduced the input dimensionality. This means less data needs to be processed and stored for each prediction, contributing directly to better scalability and faster inference times.\n",
        "*   **Robustness to Data Volume**: While training large Decision Trees can be memory-intensive, making predictions with a fixed-size, shallow Decision Tree (like ours with `max_depth=12`) scales very well with increasing numbers of prediction requests. It does not become significantly slower as the amount of data to predict on increases, as long as the data fits in memory for batch processing or can be streamed effectively.\n",
        "*   **Ease of Deployment**: Decision Trees are relatively simple to serialize and deploy using standard machine learning libraries (e.g., Python's `pickle` or `joblib`) or within containerized environments (e.g., Docker, Kubernetes) that are common in enterprise-level deployments.\n",
        "*   **Interpretable & Auditable**: For a regulatory body like the FDA, model interpretability is paramount. Decision Trees, with their rule-based structure, allow for clear auditing and explanation of why a particular prediction was made. This builds trust and facilitates compliance. Although not directly scalability, it eases the operational overhead of explaining model decisions.\n",
        "\n",
        "**In summary**, the optimized Decision Tree model is not only highly effective at meeting the FDA's safety requirements by minimizing false negatives but also possesses strong characteristics for real-world operation and scalability. Its computational efficiency, reduced feature set, and interpretable nature make it a robust candidate for practical deployment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to interprete the model"
      ],
      "metadata": {
        "id": "lSBnOS7cx8tJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b01b69b8"
      },
      "source": [
        "## Interpreting the Tuned Decision Tree Model (62 False Negatives)\n",
        "\n",
        "Our chosen Decision Tree model, meticulously tuned to minimize False Negatives, is designed to be a critical tool for the FDA. Here's how its outputs and performance should be interpreted in a real-world context:\n",
        "\n",
        "### 1. Model's Core Output\n",
        "When presented with a new mushroom sample, the model will output:\n",
        "*   **A Classification:** Either 'p' (poisonous) or 'e' (edible).\n",
        "*   **A Probability Score:** The model's confidence in its classification (e.g., 0.98 for 'poisonous', 0.02 for 'edible').\n",
        "\n",
        "### 2. The Significance of 62 False Negatives (FNs)\n",
        "\n",
        "*   **What it Means:** Out of approximately 5522 truly poisonous mushrooms in the test set, the model incorrectly classified only 62 as 'edible'. This means it missed identifying a very small fraction (about 1.1%) of potentially dangerous mushrooms.\n",
        "*   **Impact for FDA:** This is the most critical metric for the FDA. Reducing FNs from 485 to 62 signifies a monumental increase in public safety. It means the model is highly effective at preventing toxic products from being released. The risk of consumers ingesting a misclassified poisonous mushroom is significantly minimized.\n",
        "*   **Actionable Insight:** While 62 FNs is excellent, it's not zero. The FDA could establish a protocol for these rare instances, such as further human inspection or highly conservative action (e.g., discarding the batch) for any mushroom where the model's confidence for 'edible' is very low, or its confidence for 'poisonous' is non-negligible, even if the final classification is 'edible'.\n",
        "\n",
        "### 3. Understanding the Trade-off: False Positives (1484 FPs)\n",
        "\n",
        "*   **What it Means:** The model incorrectly classified 1484 truly edible mushrooms as 'poisonous'. This means that out of approximately 4607 truly edible mushrooms in the test set, about 32.2% were flagged as dangerous.\n",
        "*   **Impact for FDA:** While this number is higher than some other models, it is the deliberate cost of achieving a very low FN rate. False Positives lead to operational inefficiencies (e.g., discarding safe products, re-testing), but they **do not directly pose a public health risk**. For the FDA, this trade-off is acceptable because the safety of consumers outweighs economic costs.\n",
        "*   **Actionable Insight:** The FDA could use the probability scores associated with these FP classifications. Mushrooms with a moderate probability of being 'poisonous' (predicted by the model to be FP) could be sent for secondary, more expensive testing rather than immediate disposal, thereby optimizing resources while maintaining safety.\n",
        "\n",
        "### 4. How Feature Importance Guides Interpretation\n",
        "\n",
        "The model's decisions are primarily driven by the features `stem-width`, `cap-diameter`, `gill-color_w`, `gill-spacing_c`, and `stem-color_w`. If a mushroom has characteristics that align with known poisonous traits for these features (e.g., a specific stem width beyond a certain threshold, or a particular gill color), the model will lean towards a 'poisonous' classification. This transparency allows domain experts at the FDA to understand *why* a decision was made.\n",
        "\n",
        "### 5. Overall Interpretation for FDA Decision-Making\n",
        "\n",
        "This tuned Decision Tree model provides a robust, safety-first screening tool:\n",
        "*   **Conservative but Effective:** It is designed to be conservative when it comes to classifying a mushroom as 'edible'. It will err on the side of caution (classifying as 'poisonous') rather than missing a truly toxic one.\n",
        "*   **Risk Mitigation:** The extremely low False Negative rate means the FDA can have high confidence that products cleared by this model are genuinely safe, significantly reducing the risk of public health incidents.\n",
        "*   **Efficiency:** While not perfect, the model streamlines the initial screening process, allowing resources (human inspection, laboratory testing) to be focused on a manageable subset of potentially risky products (those flagged as 'poisonous' by the model, including the FPs, and any with uncertain probability scores).\n",
        "\n",
        "In essence, the model acts as a highly reliable 'gatekeeper,' prioritizing public safety above all else, which is the paramount concern for the FDA."
      ]
    }
  ]
}