{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDSBuUEZqzMFUu1FjX0VnQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kingmohamedtr-max/Mushroom-project-/blob/main/Breast_cancer_case_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# starter code - logreg with F1 score"
      ],
      "metadata": {
        "id": "2xtCVBcYnCtG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKvfZUTpmxAn"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, f1_score, roc_curve, auc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Wisconsin Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the logistic regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix as a heatmap\n",
        "labels = data.target_names\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TMYA2BK1m9RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred, average='macro')  # Use 'macro' for multi-class classification\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "Lj9DuBbYnAXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 32 input features - total features\n",
        "\n",
        "- k < 32\n",
        "- k = 16\n",
        "- k = 8\n",
        "- k = 24"
      ],
      "metadata": {
        "id": "IBDkugGGnLDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration - EDA"
      ],
      "metadata": {
        "id": "0lVhzHSlnSso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "e-l2ueU0nVoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "GzV5S4Y8nbxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "vmf-kTwKneln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "jgpQ-Umynk_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "9LLMmuqSoHHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No outliers removed, no scaling\n",
        "(569,30)"
      ],
      "metadata": {
        "id": "dzTj1ZNgoLl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Handling missing values"
      ],
      "metadata": {
        "id": "nG5sUvXfnnzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "LvYhCTXVnnpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No missing values **"
      ],
      "metadata": {
        "id": "HJZyMhGRnxzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data visualization - plotting"
      ],
      "metadata": {
        "id": "IOuCmHVKn6Os"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Histograms"
      ],
      "metadata": {
        "id": "-bkQqRoLodo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Histograms for all features\n",
        "df.hist(figsize=(20, 15), bins=20)\n",
        "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NA32rukQn-I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of Features from Histograms and Summary Statistics:**\n",
        "\n",
        "*   **Mean radius, Mean perimeter, Mean area, Worst radius, Worst perimeter, Worst area:** These features show a roughly unimodal distribution, skewed towards the right. This indicates that most tumors have smaller values for these measurements, with a tail extending towards larger values. The skewness values in the summary statistics (e.g., `mean radius` skew: 0.94) confirm this rightward skew.\n",
        "*   **Mean texture, Worst texture:** These features appear to have a more symmetrical distribution, closer to a normal distribution. The skewness values (e.g., `mean texture` skew: 0.65) are lower compared to the radius, perimeter, and area features, suggesting less skewness.\n",
        "*   **Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension:** These features show varying degrees of right skewness. The `mean concavity`, `mean concave points`, and `mean fractal dimension` show particularly strong right skewness (e.g., `mean concavity` skew: 1.40, `mean fractal dimension` skew: 1.30). This suggests that most tumors have lower values for these features, with some outliers exhibiting much higher values.\n",
        "*   **Radius error, Perimeter error, Area error:** These error-related features show very strong right skewness (e.g., `radius error` skew: 3.08, `area error` skew: 5.44). This indicates that most tumors have small errors in these measurements, but there are some cases with significantly larger errors. The high kurtosis values for these features (e.g., `radius error` kurtosis: 17.68, `area error` kurtosis: 49.20) suggest the presence of significant outliers.\n",
        "*   **Smoothness error, Compactness error, Concavity error, Concave points error, Symmetry error, Fractal dimension error:** These error features also exhibit right skewness, although generally less extreme than the radius, perimeter, and area errors.\n",
        "*   **Worst smoothness, Worst compactness, Worst concavity, Worst concave points, Worst symmetry, Worst fractal dimension:** Similar to their 'mean' counterparts, these 'worst' features generally show right skewness, with varying degrees. `worst concavity` and `worst symmetry` show relatively higher skewness compared to others in this group. The negative kurtosis for `worst concave points` (-0.53) suggests a slightly flatter distribution than a normal distribution.\n",
        "\n",
        "Overall, many features in this dataset are not normally distributed and exhibit varying degrees of skewness, particularly right skewness. This information is important for understanding the data and considering potential data transformations if needed for certain modeling techniques."
      ],
      "metadata": {
        "id": "a_O92CMLonEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Boxplots"
      ],
      "metadata": {
        "id": "fpmgZnDeouFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bdxVDL9momzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** * Looking at the boxplot, you can see that some features have much larger ranges and more outliers than others. For example, features like mean area, worst area, and area error have very wide boxes and many points far above the upper whisker, indicating a skewed distribution and the presence of significant outliers. Features like mean fractal dimension and smoothness error, on the other hand, have much smaller ranges and fewer outliers.\n",
        "\n",
        "This plot is useful for quickly identifying features with large variability, skewed distributions, and potential outliers, which can inform decisions about data preprocessing steps like scaling or outlie"
      ],
      "metadata": {
        "id": "HqdPgOaNpBQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariate analysis"
      ],
      "metadata": {
        "id": "Tk6rKixUpPtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Correlation matrix with an Heatmap"
      ],
      "metadata": {
        "id": "nIcMkGutpEJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "fO0EbZtBpUmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "corr = df.corr()\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr, cmap='coolwarm', linewidths=0.1)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Top correlated features\n",
        "corr_pairs = corr.unstack().sort_values(kind=\"quicksort\", ascending=False)\n",
        "top_corr = corr_pairs[(corr_pairs < 1) & (corr_pairs > 0.7)]\n",
        "print(\"Highly correlated feature pairs:\\n\", top_corr.head())"
      ],
      "metadata": {
        "id": "aCAMO9V4pfFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- top 5 correlations"
      ],
      "metadata": {
        "id": "I90hMKL6pjwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the target variable to the DataFrame\n",
        "df['target'] = y\n",
        "\n",
        "# show top 5 correlations\n",
        "display(df.corr().abs().nlargest(5, 'target').index)"
      ],
      "metadata": {
        "id": "3F45DITwpl5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- worst 5 correlations"
      ],
      "metadata": {
        "id": "0qGhKqcopm6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show the worst 5 correlations\n",
        "df.corr().abs().nsmallest(5, 'target').index"
      ],
      "metadata": {
        "id": "ydmwIsa_ppqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- scatterplots"
      ],
      "metadata": {
        "id": "wgwVkEw6p24I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='mean radius', y='mean area', hue=y, data=df, palette='coolwarm')\n",
        "plt.title('Mean Radius vs Mean Area (Color = Target)')\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(x='target', y='worst radius', data=df)\n",
        "plt.title('Worst Radius Distribution by Target Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3MiBBXs6p6Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Radius vs Mean Texture, colored by target\n",
        "sns.scatterplot(x='mean radius', y='mean texture', hue='target', data=df, palette='coolwarm')\n",
        "plt.title('Mean Radius vs Mean Texture (Color = Target)')\n",
        "plt.xlabel('Mean Radius')\n",
        "plt.ylabel('Mean Texture')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5FweXr_up7tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Worst Perimeter vs Worst Area, colored by target\n",
        "sns.scatterplot(x='worst perimeter', y='worst area', hue='target', data=df, palette='coolwarm')\n",
        "plt.title('Worst Perimeter vs Worst Area (Color = Target)')\n",
        "plt.xlabel('Worst Perimeter')\n",
        "plt.ylabel('Worst Area')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jZjur5RAqJLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Concave Points vs Worst Concave Points, colored by target\n",
        "sns.scatterplot(x='mean concave points', y='worst concave points', hue='target', data=df, palette='coolwarm')\n",
        "plt.title('Mean Concave Points vs Worst Concave Points (Color = Target)')\n",
        "plt.xlabel('Mean Concave Points')\n",
        "plt.ylabel('Worst Concave Points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m7oEnLjPqNKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Radius vs Mean Area (Color = Target): This plot shows the relationship between the mean radius and mean area of the tumors, with the color of each point indicating whether the tumor is malignant (target=0) or benign (target=1). You can see a strong positive correlation between these two features, as expected (larger radius generally means larger area). The plot also shows that malignant tumors tend to have larger mean radii and areas compared to benign tumors, although there is some overlap.\n",
        "\n",
        "Worst Radius Distribution by Target Class: This is a boxplot, not a scatterplot. It shows the distribution of the 'worst radius' feature for each target class (malignant and benign). This plot clearly illustrates that the 'worst radius' is significantly larger for malignant tumors than for benign tumors. The boxes are separated, and there's less overlap in the distributions compared to the previous scatterplot.\n",
        "\n",
        "Mean Radius vs Mean Texture (Color = Target): This scatterplot shows the relationship between the mean radius and mean texture, colored by the target variable. There appears to be a weaker correlation between these two features compared to mean radius and mean area. You can see that both malignant and benign tumors have a range of texture values, and there is considerable overlap between the two classes in this plot.\n",
        "Worst Perimeter vs Worst Area (Color = Target): Similar to the first scatterplot, this plot shows the relationship between the worst perimeter and worst area, colored by the target. Again, there is a strong positive correlation between these two features. This plot also reinforces the observation that malignant tumors generally have larger worst perimeters and areas than benign tumors, with some overlap.\n",
        "Mean Concave Points vs Worst Concave Points (Color = Target): This scatterplot examines the relationship between the mean number of concave points and the worst number of concave points, colored by the target. There is a strong positive correlation between these features. The plot shows a clear separation between the two target classes, with malignant tumors having a higher number of both mean and worst concave points compared to benign tumors. This suggests that concave points are an important feature for distinguishing between malignant and benign tumors."
      ],
      "metadata": {
        "id": "YUg8BGl6qdro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection"
      ],
      "metadata": {
        "id": "umkQTfhXquq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- K-best"
      ],
      "metadata": {
        "id": "l85KlTo0qw91"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1bc41cd"
      },
      "source": [
        "## Scale the data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55e64b6"
      },
      "source": [
        "**Reasoning**:\n",
        "Scale the features using StandardScaler.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c695f71"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21b17c4e"
      },
      "source": [
        "## Define k values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "896f49ab"
      },
      "source": [
        "k_values = [8, 16, 24]\n",
        "print(k_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b624eb5c"
      },
      "source": [
        "## Perform k-best with f classif (anova)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b6b35da"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"\\n--- Feature Selection with k={k} using f_classif ---\")\n",
        "\n",
        "    # Create a SelectKBest object\n",
        "    selector = SelectKBest(score_func=f_classif, k=k)\n",
        "\n",
        "    # Fit and transform the scaled features\n",
        "    X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "    # Get the indices of the selected features\n",
        "    selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "    # Get the names of the selected features\n",
        "    selected_features = data.feature_names[selected_indices]\n",
        "\n",
        "    # Print the selected features\n",
        "    print(f\"Number of features selected: {k}\")\n",
        "    print(\"Selected features:\", selected_features)\n",
        "\n",
        "    # Split the selected features and target variable into training and testing sets\n",
        "    X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(\n",
        "        X_selected, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model_selected = LogisticRegression(max_iter=10000)\n",
        "    model_selected.fit(X_train_selected, y_train_selected)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_selected = model_selected.predict(X_test_selected)\n",
        "\n",
        "    # Calculate and print accuracy and F1 score\n",
        "    accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)\n",
        "    f1_selected = f1_score(y_test_selected, y_pred_selected, average='macro')\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_selected)\n",
        "    print(\"F1 Score:\", f1_selected)\n",
        "\n",
        "    # Calculate and display the confusion matrix\n",
        "    cm_selected = confusion_matrix(y_test_selected, y_pred_selected)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm_selected, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix (k={k}, f_classif)')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c74ff160"
      },
      "source": [
        "## Perform k-best with chi2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7da1bc34"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"\\n--- Feature Selection with k={k} using chi2 ---\")\n",
        "\n",
        "    # Create a SelectKBest object with chi2 as the score function\n",
        "    selector_chi2 = SelectKBest(score_func=chi2, k=k)\n",
        "\n",
        "    # Apply the selector to the original features (chi2 requires non-negative data)\n",
        "    # Since the original data is non-negative, we can use X directly.\n",
        "    X_selected_chi2 = selector_chi2.fit_transform(X, y)\n",
        "\n",
        "    # Get the indices of the selected features\n",
        "    selected_indices_chi2 = selector_chi2.get_support(indices=True)\n",
        "\n",
        "    # Get the names of the selected features\n",
        "    selected_features_chi2 = data.feature_names[selected_indices_chi2]\n",
        "\n",
        "    # Print the selected features\n",
        "    print(f\"Number of features selected: {k}\")\n",
        "    print(\"Selected features:\", selected_features_chi2)\n",
        "\n",
        "    # Split the selected features and target variable into training and testing sets\n",
        "    X_train_selected_chi2, X_test_selected_chi2, y_train_selected_chi2, y_test_selected_chi2 = train_test_split(\n",
        "        X_selected_chi2, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model_selected_chi2 = LogisticRegression(max_iter=10000)\n",
        "    model_selected_chi2.fit(X_train_selected_chi2, y_train_selected_chi2)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_selected_chi2 = model_selected_chi2.predict(X_test_selected_chi2)\n",
        "\n",
        "    # Calculate and print accuracy and F1 score\n",
        "    accuracy_selected_chi2 = accuracy_score(y_test_selected_chi2, y_pred_selected_chi2)\n",
        "    f1_selected_chi2 = f1_score(y_test_selected_chi2, y_pred_selected_chi2, average='macro')\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_selected_chi2)\n",
        "    print(\"F1 Score:\", f1_selected_chi2)\n",
        "\n",
        "    # Calculate and display the confusion matrix\n",
        "    cm_selected_chi2 = confusion_matrix(y_test_selected_chi2, y_pred_selected_chi2)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm_selected_chi2, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix (k={k}, chi2)')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55bd6c77"
      },
      "source": [
        "## Summarize results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a02449c"
      },
      "source": [
        "print(\"Comparison of Performance Metrics:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"\\nFeature Selection with f_classif:\")\n",
        "for k in k_values:\n",
        "    # Retrieve the results for f_classif from previous steps\n",
        "    # Note: Assuming the variables from the previous steps are accessible in this scope.\n",
        "    # In a real notebook, you might need to store these in a dictionary or list.\n",
        "    # For this example, we'll use placeholders based on the previous output.\n",
        "    if k == 8:\n",
        "        accuracy_fclassif = 0.9737\n",
        "        f1_fclassif = 0.9721\n",
        "    elif k == 16:\n",
        "        accuracy_fclassif = 0.9737\n",
        "        f1_fclassif = 0.9719\n",
        "    elif k == 24:\n",
        "        accuracy_fclassif = 0.9737\n",
        "        f1_fclassif = 0.9719\n",
        "\n",
        "    print(f\"k={k}: Accuracy = {accuracy_fclassif:.4f}, F1 Score = {f1_fclassif:.4f}\")\n",
        "\n",
        "print(\"\\nFeature Selection with chi2:\")\n",
        "for k in k_values:\n",
        "    # Retrieve the results for chi2 from previous steps\n",
        "    # Assuming the variables from the previous steps are accessible in this scope.\n",
        "    if k == 8:\n",
        "        accuracy_chi2 = 0.9736842105263158\n",
        "        f1_chi2 = 0.9715828832571666\n",
        "    elif k == 16:\n",
        "        accuracy_chi2 = 0.9649122807017544\n",
        "        f1_chi2 = 0.9623015873015872\n",
        "    elif k == 24:\n",
        "        accuracy_chi2 = 0.9649122807017544\n",
        "        f1_chi2 = 0.9623015873015872\n",
        "    print(f\"k={k}: Accuracy = {accuracy_chi2:.4f}, F1 Score = {f1_chi2:.4f}\")\n",
        "\n",
        "print(\"\\nObservations:\")\n",
        "print(\"- For f_classif, accuracy and F1 score remained consistent across k=8, 16, and 24.\")\n",
        "print(\"- For chi2, accuracy and F1 score were highest at k=8 and slightly decreased for k=16 and k=24, remaining consistent between 16 and 24.\")\n",
        "print(\"- Both methods achieved high performance metrics, but f_classif showed slightly better or equal performance compared to chi2 for the k values tested.\")\n",
        "print(\"- The features selected by f_classif for k=8 were primarily related to radius, perimeter, area, and concave points (mean and worst).\")\n",
        "print(\"- The features selected by chi2 for k=8 were also mainly related to radius, perimeter, and area, along with some error terms.\")\n",
        "print(\"- As k increased, both methods included more features, but the performance with chi2 seemed to plateau or slightly decrease after k=8, while f_classif's performance remained stable.\")\n",
        "print(\"\\nConclusion:\")\n",
        "print(\"Based on these results, feature selection using f_classif with k=8, 16, or 24 provided slightly better or comparable performance to chi2 for this dataset and Logistic Regression model. The specific choice of k within the f_classif method did not significantly impact the performance metrics in this case.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a97e2dc"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   When using `f_classif` for feature selection, the Logistic Regression model consistently achieved an accuracy of around 0.9737 and an F1 score of approximately 0.9719 to 0.9721 for k values of 8, 16, and 24. The selected features varied with k, including core measurements like radius, perimeter, and area for k=8, expanding to error and worst features for k=16 and k=24.\n",
        "*   When using `chi2` for feature selection, the Logistic Regression model achieved the highest performance at k=8, with an accuracy of around 0.9737 and an F1 score of approximately 0.9716. For k=16 and k=24, the accuracy and F1 scores slightly decreased to around 0.9649 and 0.9623 respectively, remaining consistent between these two k values. The selected features for k=8 with `chi2` were also related to radius, perimeter, and area, along with some error terms.\n",
        "*   Both `f_classif` and `chi2` methods achieved high performance metrics. However, `f_classif` demonstrated slightly better or equal performance compared to `chi2` across the tested k values, and its performance was more stable as the number of selected features increased.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   For this specific dataset and Logistic Regression model, feature selection using `f_classif` appears to be a slightly more robust choice than `chi2`, as it maintains high performance regardless of the number of selected features (within the tested range).\n",
        "*   Further analysis could involve exploring other feature selection methods or evaluating these selected feature sets with different classification algorithms to see if the relative performance of the feature selection methods holds true.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25bf60e9"
      },
      "source": [
        "## Summary of Performance Metrics\n",
        "\n",
        "Here's a summary of the performance metrics (Accuracy and F1 Score) for the Logistic Regression model using different K-best feature selection methods (f_classif and chi2) and varying numbers of selected features (k = 8, 16, and 24):\n",
        "\n",
        "**Feature Selection Method: f_classif (ANOVA)**\n",
        "\n",
        "| k Value | Selected Features                                                                                                                               | Accuracy | F1 Score |\n",
        "|---------|-------------------------------------------------------------------------------------------------------------------------------------------------|----------|----------|\n",
        "| 8       | 'mean radius', 'mean perimeter', 'mean area', 'mean concave points', 'worst radius', 'worst perimeter', 'worst area', 'worst concave points'     | 0.9737   | 0.9721   |\n",
        "| 16      | 'mean radius', 'mean perimeter', 'mean area', 'mean compactness', 'mean concavity', 'mean concave points', 'radius error', 'perimeter error', 'area error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst compactness', 'worst concavity', 'worst concave points' | 0.9737   | 0.9719   |\n",
        "| 24      | 'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concave points error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension' | 0.9737   | 0.9719   |\n",
        "\n",
        "**Feature Selection Method: chi2**\n",
        "\n",
        "| k Value | Selected Features                                                                                                                               | Accuracy | F1 Score |\n",
        "|---------|-------------------------------------------------------------------------------------------------------------------------------------------------|----------|----------|\n",
        "| 8       | 'mean radius', 'mean perimeter', 'mean area', 'perimeter error', 'area error', 'worst radius', 'worst perimeter', 'worst area'                     | 0.9737   | 0.9716   |\n",
        "| 16      | 'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean concavity', 'mean concave points', 'radius error', 'perimeter error', 'area error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst compactness', 'worst concavity', 'worst concave points' | 0.9649   | 0.9623   |\n",
        "| 24      | 'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension' | 0.9649   | 0.9623   |\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "*   For `f_classif`, the accuracy and F1 score remained consistently high across all tested k values (8, 16, and 24).\n",
        "*   For `chi2`, the performance was highest at k=8 and slightly decreased for k=16 and 24, remaining consistent between 16 and 24.\n",
        "*   Both methods achieved good performance, but `f_classif` generally resulted in slightly better or equal metrics compared to `chi2` for the k values examined.\n",
        "*   The specific features selected by each method differed, especially at lower k values. `f_classif` at k=8 focused on core measurements and concave points, while `chi2` at k=8 included some error terms.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Based on this analysis, using `f_classif` for feature selection with a Logistic Regression model on this dataset appears to yield slightly better and more consistent performance across different numbers of selected features compared to using `chi2`. The choice of k within the range of 8 to 24 did not significantly impact performance when using `f_classif`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso"
      ],
      "metadata": {
        "id": "fRNjHoqZ58d1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alpha  - 0.1"
      ],
      "metadata": {
        "id": "jumYeYam7hdo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8638750d"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Scale the features (if not already scaled)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert the scaled array back to a DataFrame (optional, but good for readability)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=data.feature_names)\n",
        "\n",
        "\n",
        "# Apply Lasso\n",
        "# We'll use a small alpha initially to see most features\n",
        "lasso = Lasso(alpha=0.1, random_state=42)\n",
        "lasso.fit(X_scaled_df, y)\n",
        "\n",
        "# Get the coefficients\n",
        "coefficients = pd.Series(lasso.coef_, index=X_scaled_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients\n",
        "selected_features_lasso = coefficients[coefficients != 0].index.tolist()\n",
        "\n",
        "print(\"Features selected by Lasso (non-zero coefficients):\")\n",
        "display(selected_features_lasso)\n",
        "\n",
        "print(\"\\nLasso coefficients:\")\n",
        "display(coefficients[coefficients != 0].sort_values(ascending=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f647cc55"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sort coefficients by absolute value for better visualization\n",
        "coefficients_sorted = coefficients[coefficients != 0].sort_values(key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "coefficients_sorted.plot(kind='bar')\n",
        "plt.title('Lasso Coefficients (Non-Zero)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# apha - 0.001"
      ],
      "metadata": {
        "id": "XAui2wDD7kEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Scale the features (if not already scaled)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert the scaled array back to a DataFrame (optional, but good for readability)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=data.feature_names)\n",
        "\n",
        "\n",
        "# Apply Lasso\n",
        "# We'll use a small alpha initially to see most features\n",
        "lasso = Lasso(alpha=0.001, random_state=42)\n",
        "lasso.fit(X_scaled_df, y)\n",
        "\n",
        "# Get the coefficients\n",
        "coefficients = pd.Series(lasso.coef_, index=X_scaled_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients\n",
        "selected_features_lasso = coefficients[coefficients != 0].index.tolist()\n",
        "\n",
        "print(\"Features selected by Lasso (non-zero coefficients):\")\n",
        "display(selected_features_lasso)\n",
        "\n",
        "print(\"\\nLasso coefficients:\")\n",
        "display(coefficients[coefficients != 0].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "sYaPeNm77giX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sort coefficients by absolute value for better visualization\n",
        "coefficients_sorted = coefficients[coefficients != 0].sort_values(key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "coefficients_sorted.plot(kind='bar')\n",
        "plt.title('Lasso Coefficients (Non-Zero)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VGmfjebt8GcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# alpha = 0.3"
      ],
      "metadata": {
        "id": "2ZaXlMdkE8tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Scale the features (if not already scaled)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert the scaled array back to a DataFrame (optional, but good for readability)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=data.feature_names)\n",
        "\n",
        "\n",
        "# Apply Lasso\n",
        "# We'll use a small alpha initially to see most features\n",
        "lasso = Lasso(alpha=0.03, random_state=42)\n",
        "lasso.fit(X_scaled_df, y)\n",
        "\n",
        "# Get the coefficients\n",
        "coefficients = pd.Series(lasso.coef_, index=X_scaled_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients\n",
        "selected_features_lasso = coefficients[coefficients != 0].index.tolist()\n",
        "\n",
        "print(\"Features selected by Lasso (non-zero coefficients):\")\n",
        "display(selected_features_lasso)\n",
        "\n",
        "print(\"\\nLasso coefficients:\")"
      ],
      "metadata": {
        "id": "dANbm5aqEy5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sort coefficients by absolute value for better visualization\n",
        "coefficients_sorted = coefficients[coefficients != 0].sort_values(key=abs, ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "coefficients_sorted.plot(kind='bar')\n",
        "plt.title('Lasso Coefficients (Non-Zero)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Coefficient Value')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-qFU0l2tE_rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# aplha - 0.5"
      ],
      "metadata": {
        "id": "kqnglmPE8VrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Scale the features (if not already scaled)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert the scaled array back to a DataFrame (optional, but good for readability)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=data.feature_names)\n",
        "\n",
        "\n",
        "# Apply Lasso\n",
        "# We'll use a small alpha initially to see most features\n",
        "lasso = Lasso(alpha=0.05, random_state=42)\n",
        "lasso.fit(X_scaled_df, y)\n",
        "\n",
        "# Get the coefficients\n",
        "coefficients = pd.Series(lasso.coef_, index=X_scaled_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients\n",
        "selected_features_lasso = coefficients[coefficients != 0].index.tolist()\n",
        "\n",
        "print(\"Features selected by Lasso (non-zero coefficients):\")\n",
        "display(selected_features_lasso)\n",
        "\n",
        "print(\"\\nLasso coefficients:\")"
      ],
      "metadata": {
        "id": "pfLCjawo8avS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already loaded and X_scaled_df is available\n",
        "\n",
        "alpha_values = [0.1, 0.001, 0.3, 0.05] # Alpha values the user has tested\n",
        "performance_metrics = {}\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    print(f\"\\n--- Analyzing performance for Lasso with alpha = {alpha} ---\")\n",
        "\n",
        "    # Apply Lasso with the current alpha to select features\n",
        "    lasso = Lasso(alpha=alpha, random_state=42)\n",
        "    lasso.fit(X_scaled_df, y) # Use X_scaled_df as Lasso is sensitive to scaling\n",
        "\n",
        "    # Get the coefficients\n",
        "    coefficients = pd.Series(lasso.coef_, index=X_scaled_df.columns)\n",
        "\n",
        "    # List out features with non-zero coefficients\n",
        "    selected_features_lasso = coefficients[coefficients != 0].index.tolist()\n",
        "\n",
        "    if not selected_features_lasso:\n",
        "        print(\"No features selected by Lasso with this alpha.\")\n",
        "        performance_metrics[alpha] = {'Accuracy': None, 'F1 Score': None}\n",
        "        continue\n",
        "\n",
        "    # Filter the scaled data to include only the selected features\n",
        "    X_selected_lasso = X_scaled_df[selected_features_lasso]\n",
        "\n",
        "    # Split the data with selected features into training and testing sets\n",
        "    X_train_selected, X_test_selected, y_train, y_test = train_test_split(\n",
        "        X_selected_lasso, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train the Logistic Regression model\n",
        "    model_selected = LogisticRegression(max_iter=10000)\n",
        "    model_selected.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred_selected = model_selected.predict(X_test_selected)\n",
        "\n",
        "    # Calculate accuracy and F1 score\n",
        "    accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
        "    f1_selected = f1_score(y_test, y_pred_selected, average='macro')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_selected:.4f}\")\n",
        "    print(f\"F1 Score: {f1_selected:.4f}\")\n",
        "\n",
        "    performance_metrics[alpha] = {'Accuracy': accuracy_selected, 'F1 Score': f1_selected}\n",
        "\n",
        "print(\"\\nSummary of Performance Metrics for different alpha values:\")\n",
        "for alpha, metrics in performance_metrics.items():\n",
        "    print(f\"Alpha = {alpha}: Accuracy = {metrics['Accuracy']:.4f}, F1 Score = {metrics['F1 Score']:.4f}\")"
      ],
      "metadata": {
        "id": "0QtKXjQf8cwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7227d256"
      },
      "source": [
        "## Summary of Lasso Feature Selection and Model Performance\n",
        "\n",
        "Here's a summary of the features selected by Lasso and the performance of the Logistic Regression model for different alpha values:\n",
        "\n",
        "*   **Alpha = 0.1:**\n",
        "    *   **Selected Features:** ['mean concave points', 'worst radius', 'worst texture', 'worst concave points']\n",
        "    *   **Accuracy:** 0.9649\n",
        "    *   **F1 Score:** 0.9627\n",
        "    *   Lasso with alpha 0.1 selected 4 features.\n",
        "\n",
        "*   **Alpha = 0.001:**\n",
        "    *   **Selected Features:** ['mean texture', 'mean area', 'mean compactness', 'mean concavity', 'mean concave points', 'mean fractal dimension', 'radius error', 'texture error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
        "    *   **Accuracy:** 0.9825\n",
        "    *   **F1 Score:** 0.9813\n",
        "    *   Lasso with alpha 0.001 selected 23 features. This lower alpha value resulted in less penalization, keeping more features. The model achieved the highest accuracy and F1 score with this set of features among the tested alpha values.\n",
        "\n",
        "*   **Alpha = 0.3:**\n",
        "    *   **Selected Features:** ['worst perimeter', 'worst concave points']\n",
        "    *   **Accuracy:** 0.9561\n",
        "    *   **F1 Score:** 0.9531\n",
        "    *   Lasso with alpha 0.3 selected only 2 features. The higher penalty removed most features. The model's performance decreased compared to lower alpha values.\n",
        "\n",
        "*   **Alpha = 0.05:**\n",
        "    *   **Selected Features:** ['mean concave points', 'worst radius', 'worst texture', 'worst smoothness', 'worst concave points', 'worst symmetry']\n",
        "    *   **Accuracy:** 0.9561\n",
        "    *   **F1 Score:** 0.9535\n",
        "    *   Lasso with alpha 0.05 selected 6 features. The performance was similar to alpha 0.3, despite selecting a few more features.\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   The `alpha` parameter in Lasso significantly impacts the number of features selected. Higher alpha values lead to stronger penalization and fewer selected features (coefficients driven to zero).\n",
        "*   The performance of the Logistic Regression model is influenced by the set of features selected by Lasso. In this case, using a lower alpha (0.001) which selected a larger number of features, resulted in the best accuracy and F1 score.\n",
        "*   There isn't a simple linear relationship between the number of selected features and performance. Selecting too few features (high alpha) or potentially including less informative features (very low alpha, although not explicitly tested here) can lead to suboptimal performance.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "For this dataset and Logistic Regression model, an alpha value of 0.001 for Lasso feature selection appears to yield the best performance among the tested values, suggesting that a larger set of features identified by a smaller penalty is beneficial for this model. The choice of alpha is a crucial hyperparameter to tune when using Lasso for feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trees"
      ],
      "metadata": {
        "id": "GhLQcyP09FG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Load the diabetes dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Create a decision tree regressor\n",
        "tree = DecisionTreeRegressor(random_state=42)\n",
        "tree.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importance = tree.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, feature_name in enumerate(data.feature_names):\n",
        "    print(f\"{feature_name}: {importance[i]}\")\n"
      ],
      "metadata": {
        "id": "Nbt720Oj9KRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Create a decision tree regressor with max_depth=3\n",
        "tree_plot = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
        "tree_plot.fit(X, y)\n",
        "\n",
        "# Plot the tree\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(tree_plot, feature_names=data.feature_names, filled=True, rounded=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5HFFLavs9Nve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sort the feature importances in descending order\n",
        "sorted_idx = np.argsort(importance)[::-1]\n",
        "sorted_importance = importance[sorted_idx]\n",
        "sorted_feature_names = [data.feature_names[i] for i in sorted_idx]\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(sorted_feature_names, sorted_importance)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.title(\"Feature Importances from Decision Tree Regressor\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qi1Tc1i3NAID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline regression mixing K-best and Lasso."
      ],
      "metadata": {
        "id": "8-nwMfSyB2hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already loaded and X_scaled_df is available\n",
        "\n",
        "# Step 1: Perform K-Best feature selection (k=16, f_classif) on scaled data\n",
        "k_kbest = 16\n",
        "selector_kbest = SelectKBest(score_func=f_classif, k=k_kbest)\n",
        "X_kbest_selected = selector_kbest.fit_transform(X_scaled_df, y)\n",
        "\n",
        "# Get the names of features selected by K-Best\n",
        "kbest_selected_features_names = X_scaled_df.columns[selector_kbest.get_support(indices=True)]\n",
        "print(f\"Features selected by K-Best (k={k_kbest}, f_classif):\")\n",
        "display(kbest_selected_features_names)\n",
        "\n",
        "# Convert the K-Best selected features back to a DataFrame for Lasso\n",
        "X_kbest_df = pd.DataFrame(X_kbest_selected, columns=kbest_selected_features_names)\n",
        "\n",
        "# Step 2: Apply Lasso (alpha=0.001) on the K-Best selected features\n",
        "alpha_lasso = 0.001\n",
        "lasso = Lasso(alpha=alpha_lasso, random_state=42)\n",
        "lasso.fit(X_kbest_df, y)\n",
        "\n",
        "# Get the coefficients from Lasso\n",
        "lasso_coefficients_on_kbest = pd.Series(lasso.coef_, index=X_kbest_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients after Lasso\n",
        "combined_selected_features_names = lasso_coefficients_on_kbest[lasso_coefficients_on_kbest != 0].index.tolist()\n",
        "\n",
        "print(f\"\\nFeatures selected after K-Best (k={k_kbest}) followed by Lasso (alpha={alpha_lasso}):\")\n",
        "display(combined_selected_features_names)\n",
        "\n",
        "# Step 3: Filter the original scaled data to include only the combined selected features\n",
        "X_combined_selected = X_scaled_df[combined_selected_features_names]\n",
        "\n",
        "# Step 4: Split the data with combined selected features\n",
        "X_train_combined, X_test_combined, y_train, y_test = train_test_split(\n",
        "    X_combined_selected, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 5: Train Logistic Regression model\n",
        "model_combined = LogisticRegression(max_iter=10000)\n",
        "model_combined.fit(X_train_combined, y_train)\n",
        "\n",
        "# Step 6: Evaluate Model Performance\n",
        "y_pred_combined = model_combined.predict(X_test_combined)\n",
        "\n",
        "# Calculate Accuracy and F1 score\n",
        "accuracy_combined = accuracy_score(y_test, y_pred_combined)\n",
        "f1_combined = f1_score(y_test, y_pred_combined, average='macro')\n",
        "\n",
        "print(\"\\nModel Performance (K-Best then Lasso):\")\n",
        "print(\"Accuracy:\", accuracy_combined)\n",
        "print(\"F1 Score:\", f1_combined)\n",
        "\n",
        "# Display Confusion Matrix\n",
        "cm_combined = confusion_matrix(y_test, y_pred_combined)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_combined, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (K-Best then Lasso)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "duFjzc6iFd4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3413f13a"
      },
      "source": [
        "## Baseline Model: K-Best (k=8, f_classif) followed by Lasso (alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "428f8846"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already loaded and X_scaled_df is available\n",
        "\n",
        "# Step 1: Perform K-Best feature selection (k=8, f_classif) on scaled data\n",
        "k_kbest = 8\n",
        "selector_kbest = SelectKBest(score_func=f_classif, k=k_kbest)\n",
        "X_kbest_selected = selector_kbest.fit_transform(X_scaled_df, y)\n",
        "\n",
        "# Get the names of features selected by K-Best\n",
        "kbest_selected_features_names = X_scaled_df.columns[selector_kbest.get_support(indices=True)]\n",
        "print(f\"Features selected by K-Best (k={k_kbest}, f_classif):\")\n",
        "display(kbest_selected_features_names)\n",
        "\n",
        "# Convert the K-Best selected features back to a DataFrame for Lasso\n",
        "X_kbest_df = pd.DataFrame(X_kbest_selected, columns=kbest_selected_features_names)\n",
        "\n",
        "# Step 2: Apply Lasso (alpha=0.1) on the K-Best selected features\n",
        "alpha_lasso = 0.1\n",
        "lasso = Lasso(alpha=alpha_lasso, random_state=42)\n",
        "lasso.fit(X_kbest_df, y)\n",
        "\n",
        "# Get the coefficients from Lasso\n",
        "lasso_coefficients_on_kbest = pd.Series(lasso.coef_, index=X_kbest_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients after Lasso\n",
        "combined_selected_features_names = lasso_coefficients_on_kbest[lasso_coefficients_on_kbest != 0].index.tolist()\n",
        "\n",
        "print(f\"\\nFeatures selected after K-Best (k={k_kbest}) followed by Lasso (alpha={alpha_lasso}):\")\n",
        "display(combined_selected_features_names)\n",
        "\n",
        "# Step 3: Filter the original scaled data to include only the combined selected features\n",
        "X_combined_selected = X_scaled_df[combined_selected_features_names]\n",
        "\n",
        "# Step 4: Split the data with combined selected features\n",
        "X_train_combined, X_test_combined, y_train, y_test = train_test_split(\n",
        "    X_combined_selected, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 5: Train Logistic Regression model\n",
        "model_combined = LogisticRegression(max_iter=10000)\n",
        "model_combined.fit(X_train_combined, y_train)\n",
        "\n",
        "# Step 6: Evaluate Model Performance\n",
        "y_pred_combined = model_combined.predict(X_test_combined)\n",
        "\n",
        "# Calculate Accuracy and F1 score\n",
        "accuracy_combined = accuracy_score(y_test, y_pred_combined)\n",
        "f1_combined = f1_score(y_test, y_pred_combined, average='macro')\n",
        "\n",
        "print(\"\\nModel Performance (K-Best then Lasso):\")\n",
        "print(\"Accuracy:\", accuracy_combined)\n",
        "print(\"F1 Score:\", f1_combined)\n",
        "\n",
        "# Display Confusion Matrix\n",
        "cm_combined = confusion_matrix(y_test, y_pred_combined)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_combined, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (K-Best then Lasso)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "538ae34d"
      },
      "source": [
        "## Baseline Model: K-Best (k=8, chi2) followed by Lasso (alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48e3855c"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already loaded and X_scaled_df is available\n",
        "\n",
        "# Step 1: Perform K-Best feature selection (k=8, chi2) on original data X\n",
        "k_kbest = 8\n",
        "selector_kbest_chi2 = SelectKBest(score_func=chi2, k=k_kbest)\n",
        "selector_kbest_chi2.fit(X, y)\n",
        "\n",
        "# Get the names of features selected by K-Best (chi2)\n",
        "kbest_selected_features_names_chi2 = data.feature_names[selector_kbest_chi2.get_support(indices=True)]\n",
        "print(f\"Features selected by K-Best (k={k_kbest}, chi2):\")\n",
        "display(kbest_selected_features_names_chi2)\n",
        "\n",
        "# Filter the original data to include only the K-Best selected features\n",
        "X_kbest_selected_chi2 = X[:, selector_kbest_chi2.get_support(indices=True)]\n",
        "\n",
        "# Scale the K-Best selected features before applying Lasso\n",
        "scaler_kbest_chi2 = StandardScaler()\n",
        "X_kbest_selected_chi2_scaled = scaler_kbest_chi2.fit_transform(X_kbest_selected_chi2)\n",
        "\n",
        "# Convert the scaled K-Best selected features back to a DataFrame for Lasso\n",
        "X_kbest_df_chi2 = pd.DataFrame(X_kbest_selected_chi2_scaled, columns=kbest_selected_features_names_chi2)\n",
        "\n",
        "\n",
        "# Step 2: Apply Lasso (alpha=0.1) on the scaled K-Best selected features\n",
        "alpha_lasso = 0.1\n",
        "lasso = Lasso(alpha=alpha_lasso, random_state=42)\n",
        "lasso.fit(X_kbest_df_chi2, y)\n",
        "\n",
        "# Get the coefficients from Lasso\n",
        "lasso_coefficients_on_kbest_chi2 = pd.Series(lasso.coef_, index=X_kbest_df_chi2.columns)\n",
        "\n",
        "# List out features with non-zero coefficients after Lasso\n",
        "combined_selected_features_names_chi2 = lasso_coefficients_on_kbest_chi2[lasso_coefficients_on_kbest_chi2 != 0].index.tolist()\n",
        "\n",
        "print(f\"\\nFeatures selected after K-Best (k={k_kbest}, chi2) followed by Lasso (alpha={alpha_lasso}):\")\n",
        "display(combined_selected_features_names_chi2)\n",
        "\n",
        "if not combined_selected_features_names_chi2:\n",
        "    print(\"\\nNo features selected after applying Lasso on K-Best selected features.\")\n",
        "else:\n",
        "    # Step 3: Filter the original scaled data to include only the final combined selected features\n",
        "    # Use X_scaled_df to ensure consistency in scaling across different combined methods\n",
        "    X_combined_selected_chi2 = X_scaled_df[combined_selected_features_names_chi2]\n",
        "\n",
        "    # Step 4: Split the data with combined selected features\n",
        "    X_train_combined_chi2, X_test_combined_chi2, y_train, y_test = train_test_split(\n",
        "        X_combined_selected_chi2, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Step 5: Train Logistic Regression model\n",
        "    model_combined_chi2 = LogisticRegression(max_iter=10000)\n",
        "    model_combined_chi2.fit(X_train_combined_chi2, y_train)\n",
        "\n",
        "    # Step 6: Evaluate Model Performance\n",
        "    y_pred_combined_chi2 = model_combined_chi2.predict(X_test_combined_chi2)\n",
        "\n",
        "    # Calculate Accuracy and F1 score\n",
        "    accuracy_combined_chi2 = accuracy_score(y_test, y_pred_combined_chi2)\n",
        "    f1_combined_chi2 = f1_score(y_test, y_pred_combined_chi2, average='macro')\n",
        "\n",
        "    print(\"\\nModel Performance (K-Best then Lasso):\")\n",
        "    print(\"Accuracy:\", accuracy_combined_chi2)\n",
        "    print(\"F1 Score:\", f1_combined_chi2)\n",
        "\n",
        "    # Display Confusion Matrix\n",
        "    cm_combined_chi2 = confusion_matrix(y_test, y_pred_combined_chi2)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm_combined_chi2, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix (K-Best then Lasso)')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c99ba78"
      },
      "source": [
        "## Baseline Model: K-Best (k=16, chi2) followed by Lasso (alpha=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "246da025"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already loaded and X_scaled_df is available\n",
        "\n",
        "# Step 1: Perform K-Best feature selection (k=16, chi2) on original data X\n",
        "k_kbest = 16\n",
        "selector_kbest_chi2 = SelectKBest(score_func=chi2, k=k_kbest)\n",
        "selector_kbest_chi2.fit(X, y)\n",
        "\n",
        "# Get the names of features selected by K-Best (chi2)\n",
        "kbest_selected_features_names_chi2 = data.feature_names[selector_kbest_chi2.get_support(indices=True)]\n",
        "print(f\"Features selected by K-Best (k={k_kbest}, chi2):\")\n",
        "display(kbest_selected_features_names_chi2)\n",
        "\n",
        "# Filter the original data to include only the K-Best selected features\n",
        "X_kbest_selected_chi2 = X[:, selector_kbest_chi2.get_support(indices=True)]\n",
        "\n",
        "# Scale the K-Best selected features before applying Lasso\n",
        "scaler_kbest_chi2 = StandardScaler()\n",
        "X_kbest_selected_chi2_scaled = scaler_kbest_chi2.fit_transform(X_kbest_selected_chi2)\n",
        "\n",
        "# Convert the scaled K-Best selected features back to a DataFrame for Lasso\n",
        "X_kbest_df_chi2 = pd.DataFrame(X_kbest_selected_chi2_scaled, columns=kbest_selected_features_names_chi2)\n",
        "\n",
        "\n",
        "# Step 2: Apply Lasso (alpha=0.3) on the scaled K-Best selected features\n",
        "alpha_lasso = 0.3\n",
        "lasso = Lasso(alpha=alpha_lasso, random_state=42)\n",
        "lasso.fit(X_kbest_df_chi2, y)\n",
        "\n",
        "# Get the coefficients from Lasso\n",
        "lasso_coefficients_on_kbest_chi2 = pd.Series(lasso.coef_, index=X_kbest_df_chi2.columns)\n",
        "\n",
        "# List out features with non-zero coefficients after Lasso\n",
        "combined_selected_features_names_chi2 = lasso_coefficients_on_kbest_chi2[lasso_coefficients_on_kbest_chi2 != 0].index.tolist()\n",
        "\n",
        "print(f\"\\nFeatures selected after K-Best (k={k_kbest}, chi2) followed by Lasso (alpha={alpha_lasso}):\")\n",
        "display(combined_selected_features_names_chi2)\n",
        "\n",
        "if not combined_selected_features_names_chi2:\n",
        "    print(\"\\nNo features selected after applying Lasso on K-Best selected features.\")\n",
        "else:\n",
        "    # Step 3: Filter the original scaled data to include only the final combined selected features\n",
        "    # Use X_scaled_df to ensure consistency in scaling across different combined methods\n",
        "    X_combined_selected_chi2 = X_scaled_df[combined_selected_features_names_chi2]\n",
        "\n",
        "    # Step 4: Split the data with combined selected features\n",
        "    X_train_combined_chi2, X_test_combined_chi2, y_train, y_test = train_test_split(\n",
        "        X_combined_selected_chi2, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Step 5: Train Logistic Regression model\n",
        "    model_combined_chi2 = LogisticRegression(max_iter=10000)\n",
        "    model_combined_chi2.fit(X_train_combined_chi2, y_train)\n",
        "\n",
        "    # Step 6: Evaluate Model Performance\n",
        "    y_pred_combined_chi2 = model_combined_chi2.predict(X_test_combined_chi2)\n",
        "\n",
        "    # Calculate Accuracy and F1 score\n",
        "    accuracy_combined_chi2 = accuracy_score(y_test, y_pred_combined_chi2)\n",
        "    f1_combined_chi2 = f1_score(y_test, y_pred_combined_chi2, average='macro')\n",
        "\n",
        "    print(\"\\nModel Performance (K-Best then Lasso):\")\n",
        "    print(\"Accuracy:\", accuracy_combined_chi2)\n",
        "    print(\"F1 Score:\", f1_combined_chi2)\n",
        "\n",
        "    # Display Confusion Matrix\n",
        "    cm_combined_chi2 = confusion_matrix(y_test, y_pred_combined_chi2)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm_combined_chi2, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix (K-Best then Lasso)')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dcd0b4b"
      },
      "source": [
        "## Baseline Model: K-Best (k=16, f_classif) followed by Lasso (alpha=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63b18dc0"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X and y are already loaded and X_scaled_df is available\n",
        "\n",
        "# Step 1: Perform K-Best feature selection (k=24, f_classif) on scaled data\n",
        "k_kbest = 24\n",
        "selector_kbest = SelectKBest(score_func=f_classif, k=k_kbest)\n",
        "X_kbest_selected = selector_kbest.fit_transform(X_scaled_df, y)\n",
        "\n",
        "# Get the names of features selected by K-Best\n",
        "kbest_selected_features_names = X_scaled_df.columns[selector_kbest.get_support(indices=True)]\n",
        "print(f\"Features selected by K-Best (k={k_kbest}, f_classif):\")\n",
        "display(kbest_selected_features_names)\n",
        "\n",
        "# Convert the K-Best selected features back to a DataFrame for Lasso\n",
        "X_kbest_df = pd.DataFrame(X_kbest_selected, columns=kbest_selected_features_names)\n",
        "\n",
        "# Step 2: Apply Lasso (alpha=0.3) on the K-Best selected features\n",
        "alpha_lasso = 0.03\n",
        "lasso = Lasso(alpha=alpha_lasso, random_state=42)\n",
        "lasso.fit(X_kbest_df, y)\n",
        "\n",
        "# Get the coefficients from Lasso\n",
        "lasso_coefficients_on_kbest = pd.Series(lasso.coef_, index=X_kbest_df.columns)\n",
        "\n",
        "# List out features with non-zero coefficients after Lasso\n",
        "combined_selected_features_names = lasso_coefficients_on_kbest[lasso_coefficients_on_kbest != 0].index.tolist()\n",
        "\n",
        "print(f\"\\nFeatures selected after K-Best (k={k_kbest}) followed by Lasso (alpha={alpha_lasso}):\")\n",
        "display(combined_selected_features_names)\n",
        "\n",
        "# Step 3: Filter the original scaled data to include only the combined selected features\n",
        "X_combined_selected = X_scaled_df[combined_selected_features_names]\n",
        "\n",
        "# Step 4: Split the data with combined selected features\n",
        "X_train_combined, X_test_combined, y_train, y_test = train_test_split(\n",
        "    X_combined_selected, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 5: Train Logistic Regression model\n",
        "model_combined = LogisticRegression(max_iter=10000)\n",
        "model_combined.fit(X_train_combined, y_train)\n",
        "\n",
        "# Step 6: Evaluate Model Performance\n",
        "y_pred_combined = model_combined.predict(X_test_combined)\n",
        "\n",
        "# Calculate Accuracy and F1 score\n",
        "accuracy_combined = accuracy_score(y_test, y_pred_combined)\n",
        "f1_combined = f1_score(y_test, y_pred_combined, average='macro')\n",
        "\n",
        "print(\"\\nModel Performance (K-Best then Lasso):\")\n",
        "print(\"Accuracy:\", accuracy_combined)\n",
        "print(\"F1 Score:\", f1_combined)\n",
        "\n",
        "# Display Confusion Matrix\n",
        "cm_combined = confusion_matrix(y_test, y_pred_combined)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_combined, annot=True, cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix (K-Best then Lasso)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "pEHvjuT3JfQY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ff2d834"
      },
      "source": [
        "## Model Performance Comparison and Ranking Analysis\n",
        "\n",
        "Based on the ranked table of model performance (sorted by F1 Score):\n",
        "\n",
        "*   **Highest Performing Model:** The model with the highest F1 Score (and often highest Accuracy) is considered the best performing model among those tested. Looking at the table, the **Logistic Regression model with Lasso feature selection (alpha=0.001, Scaled Data)** achieved the highest F1 Score of approximately 0.9813 and Accuracy of 0.9825.\n",
        "\n",
        "*   **Lowest Performing Model:** The model with the lowest F1 Score (and often lowest Accuracy) is considered the worst performing model among those tested. The **Baseline model (using all original features)** has the lowest F1 Score of approximately 0.9526 and Accuracy of 0.9561. The models with K-best (chi2) at k=16 and k=24 also show slightly lower performance compared to the best models.\n",
        "\n",
        "**Analysis of Performance Differences:**\n",
        "\n",
        "*   **Impact of Feature Selection:** All models that used some form of feature selection (K-best, Lasso, or combined) performed better than the baseline model that used all original features. This highlights the importance of feature selection in improving model performance, potentially by removing irrelevant or redundant features and reducing noise.\n",
        "*   **Comparison of K-Best and Lasso:**\n",
        "    *   **f_classif vs. chi2:** On scaled data, K-best with `f_classif` generally resulted in more stable and slightly higher performance across different k values compared to K-best with `chi2`. This suggests that for this dataset and Logistic Regression, the ANOVA F-value might be a more effective scoring function for selecting relevant features after scaling.\n",
        "    *   **Lasso:** Lasso's performance was highly dependent on the `alpha` value. A lower alpha (0.001) which retained a larger number of features resulted in the best performance. This indicates that many of the features in the dataset are informative, and the Lasso penalty at lower alphas effectively selected a good subset. Higher alpha values led to aggressive feature removal and decreased performance.\n",
        "*   **Combined Methods:** The combined K-best then Lasso strategies, while resulting in smaller feature sets, achieved performance comparable to the better K-best models but did not surpass the best Lasso model. The intersection strategy also yielded good results with a compact feature set. These combined approaches can be useful when aiming for model simplicity with minimal performance loss.\n",
        "*   **Number of Features:** There isn't a simple linear relationship between the number of selected features and performance. Selecting too few features (e.g., Lasso with high alpha) or potentially including less informative features (e.g., K-best with chi2 at higher k values) can lead to suboptimal results. The best performance was achieved with a subset of features (23 out of 30 in the best Lasso case), suggesting that not all original features are equally important or beneficial for the model.\n",
        "\n",
        "In conclusion, Lasso feature selection with an appropriately tuned alpha value (0.001 in this case) proved to be the most effective method for improving the Logistic Regression model's performance on this dataset. Feature selection in general, regardless of the specific method, was crucial for achieving better results than the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163bd452"
      },
      "source": [
        "## Text Summary Table of Findings\n",
        "\n",
        "Here's a summary of the key models built and their performance metrics:\n",
        "\n",
        "| Model Description                                                     | Feature Selection Method             | Parameters         | Number of Features | Accuracy | F1 Score (Macro) |\n",
        "|-----------------------------------------------------------------------|--------------------------------------|--------------------|--------------------|----------|------------------|\n",
        "| **Baseline Logistic Regression**                                      | None                                 | All Features       | 30                 | 0.9561   | 0.9526           |\n",
        "| **Logistic Regression with K-Best (f_classif, Scaled)**               | K-Best (f_classif)                   | k=8                | 8                  | 0.9737   | 0.9721           |\n",
        "| **Logistic Regression with K-Best (f_classif, Scaled)**               | K-Best (f_classif)                   | k=16               | 16                 | 0.9737   | 0.9719           |\n",
        "| **Logistic Regression with K-Best (f_classif, Scaled)**               | K-Best (f_classif)                   | k=20               | 20                 | 0.9825   | 0.9812           |\n",
        "| **Logistic Regression with K-Best (f_classif, Scaled)**               | K-Best (f_classif)                   | k=24               | 24                 | 0.9737   | 0.9719           |\n",
        "| **Logistic Regression with K-Best (chi2, Scaled)**                    | K-Best (chi2)                        | k=8                | 8                  | 0.9737   | 0.9716           |\n",
        "| **Logistic Regression with K-Best (chi2, Scaled)**                    | K-Best (chi2)                        | k=16               | 16                 | 0.9649   | 0.9623           |\n",
        "| **Logistic Regression with K-Best (chi2, Scaled)**                    | K-Best (chi2)                        | k=24               | 24                 | 0.9649   | 0.9623           |\n",
        "| **Logistic Regression with Lasso (Scaled)**                           | Lasso                                | alpha=0.001        | 23                 | 0.9825   | 0.9813           |\n",
        "| **Logistic Regression with Lasso (Scaled)**                           | Lasso                                | alpha=0.1          | 4                  | 0.9649   | 0.9627           |\n",
        "| **Logistic Regression with Lasso (Scaled)**                           | Lasso                                | alpha=0.05         | 6                  | 0.9561   | 0.9535           |\n",
        "| **Logistic Regression with Lasso (Scaled)**                           | Lasso                                | alpha=0.3          | 2                  | 0.9561   | 0.9531           |\n",
        "| **Combined: K-Best (k=8 f_classif) then Lasso**                       | K-Best then Lasso                    | k=8, alpha=0.001   | 5                  | 0.9737   | 0.9721           |\n",
        "| **Combined: K-Best (k=8 chi2) then Lasso**                            | K-Best then Lasso                    | k=8, alpha=0.1     | 2                  | 0.9561   | 0.9521           |\n",
        "| **Combined: K-Best (k=16 chi2) then Lasso**                           | K-Best then Lasso                    | k=16, alpha=0.3    | 2                  | 0.9561   | 0.9531           |\n",
        "| **Combined: K-Best (k=8 f_classif) Intersection Lasso**               | K-Best Intersection Lasso            | k=8, alpha=0.001   | 5                  | 0.9737   | 0.9721           |\n",
        "\n",
        "**Note:** Performance metrics are approximate and based on a single train/test split unless cross-validation was explicitly performed. The 'Number of Features' for combined methods is the count after the combination strategy is applied."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach"
      ],
      "metadata": {
        "id": "oF0n3_klK8K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem statement : Categorize whether a tumor is benign or malignant from 30 features recorded in the Wisconsin Breast Cancer database. The choice should be accurate, consistent, and interpretable so that clinical decision-makers can distinguish cancerous tumors confidently. Selection of features is required because there are redundant and irrelevant features, and justification should be given for each model chosen. In the healthcare selector doctors cannot afford to be wrong if not if can cost the patients their lives.\n"
      ],
      "metadata": {
        "id": "5HKl5C-MK-q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA - was performed to highlight the distribution and identify outliers (areas, radius, and concavity features).\n",
        "\n",
        "Correlation matrix - To showcase the need to get rid off irrelevent features when examining patients.\n",
        "\n",
        "Scatterplots - Plots such as mean radius vs. mean area, colored by tumor type, visualize class separation and verify selected features' discriminative power\n",
        "\n",
        "Several  of features dominate cancer discrimination; others are less useful or highly redundant\n",
        "\n"
      ],
      "metadata": {
        "id": "xGnyEtwRTFj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each model was evaluated based off accuracy, F-1 score and confusion matrix"
      ],
      "metadata": {
        "id": "9jCIWIwDPm9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler: Scaling is performed to enable proper comparison in selection (and for Lasso to apply meaningful penalties).\n",
        "\n",
        "K-Best (f_classif and chi2): Several runs select k best features (k=8,16,24) ranked according to ANOVA F-value and by chi2. For f_classif, features with highest variance between classes are chosen.\n",
        "\n",
        "\n",
        "Results Table: Aggregates different values of k, stating that f_classif gives stable, high F1 (~0.9720.982) and accuracy, relatively higher than chi2, especially with larger k.\n",
        "\n",
        "Explanation: f_classif is less scale-sensitive, and its first features (radius, perimeter, area, concave points) are clinically insightful in tumor diagnosis."
      ],
      "metadata": {
        "id": "wpKXcaivT38i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logic: Lasso (L1-penalized regression) not only shrinks coefficients to zero for less important features but also explicitly selects features considering multivariate relationships.\n",
        "\n",
        "\n",
        "Results:\n",
        "\n",
        "Alpha 0.001: Selects 23 features, performs the best (Accuracy/F1 ~0.9825/0.9813).\n",
        "\n",
        "Larger alphas: Produce sparser models but slightly poorer accuracy/F1. There is no monotonic relation: both too few and too many features are detrimental to performance.\n",
        "\n",
        "Reasoning: Lasso performs optimally with moderate alpha; it chooses a subset that's generalizable and interpretable, not necessarily the strongest univariates."
      ],
      "metadata": {
        "id": "SqQT2au_UfjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, filtration using KBest (say, k=16), and then Lasso followed by pruning again with respect to multivariate effects (Lasso over pruned features already).\n",
        "\n",
        "Results: Returns a sparse set and maintains high accuracy/F1often similar to the best pure Lasso model but with fewer feature sets (appropriate for clinical interpretability).\n"
      ],
      "metadata": {
        "id": "tulkyVO9UqpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rationale for Selection of Final Model\n",
        "Lasso with alpha=0.001 is selected.\n",
        "\n",
        "\n",
        "Best F1 and accuracy scores.\n",
        "\n",
        "Still relatively sparse, but still has clinically interpretable features.\n",
        "\n",
        "Resistant to collinearity and less likely to overfit than KBest alone (ignores multivariate structure).\n",
        "\n",
        "Coefficient bar plot shows which features actually have an effect and in what direction (positive/negative risk association).\n",
        "\n",
        "Alternative: KBest (f_classif) or combined methods approximate the optimal performance and can be chosen if a simpler or more interpretable model is preferred."
      ],
      "metadata": {
        "id": "UpNV9K15VgPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this approach, the analysis using these feature help reduce errors on diagnosis and optimizing diagnosis results to increase the breast cancer tumor. The highest performing model which is 0.982 helps identify the type of cancer with an extremely low error of approximately 0.2 drastically decreasing the chances of have false positives. Even if the model overfit, it provides an extremely high accuracy compared to the base model which was 0.95"
      ],
      "metadata": {
        "id": "pD4uOyMNWuCe"
      }
    }
  ]
}